{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b936d810",
   "metadata": {},
   "source": [
    "# Quilter Senior AI Scientist Challenge – Advisor Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2156477",
   "metadata": {},
   "source": [
    "Kai Glahome\n",
    "21/02/2026\n",
    "\n",
    "Design decisions, evaluation strategy, and reflections on further improvements are covered in the accompanying documentation.\n",
    "\n",
    "\n",
    "To run:\n",
    "\n",
    "- Place the source Quilter PDF documents in a folder named `quilter_pdfs_advisor_support_material` at the project root.\n",
    "- Add your OpenAI API key in a `.env` file at the project root:  \n",
    "  `OPENAI_API_KEY=your_api_key_here`\n",
    "- Run the notebook from the start. The notebook will:\n",
    "  - Ingest and process the PDFs\n",
    "  - Build the Chroma vector database automatically\n",
    "  - Provide the interactive assistant interface\n",
    "\n",
    "I ran on Python 3.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6513b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in ./.venv/lib/python3.12/site-packages (0.11.5)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.1.4)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: fastapi in ./.venv/lib/python3.12/site-packages (0.115.11)\n",
      "Requirement already satisfied: uvicorn in ./.venv/lib/python3.12/site-packages (0.34.0)\n",
      "Requirement already satisfied: nest-asyncio in ./.venv/lib/python3.12/site-packages (1.5.6)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.66.3)\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.12/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-core in ./.venv/lib/python3.12/site-packages (0.3.45)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.12/site-packages (0.3.8)\n",
      "Requirement already satisfied: langchain-chroma in ./.venv/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: langchain-text-splitters in ./.venv/lib/python3.12/site-packages (0.3.6)\n",
      "Requirement already satisfied: chromadb in ./.venv/lib/python3.12/site-packages (0.4.22)\n",
      "Requirement already satisfied: rank-bm25 in ./.venv/lib/python3.12/site-packages (0.2.2)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in ./.venv/lib/python3.12/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in ./.venv/lib/python3.12/site-packages (from pdfplumber) (12.1.1)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in ./.venv/lib/python3.12/site-packages (from pdfplumber) (5.5.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./.venv/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./.venv/lib/python3.12/site-packages (from pdfminer.six==20231228->pdfplumber) (46.0.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from fastapi) (0.46.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from fastapi) (2.12.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.12/site-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.12.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.11)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.12/site-packages (from uvicorn) (8.3.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.12/site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.13.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai) (4.67.3)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain) (0.3.45)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain) (2.0.46)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-core) (9.1.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.6.3)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.3.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.12/site-packages (from langchain-openai) (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2026.1.15)\n",
      "Requirement already satisfied: build>=1.0.3 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.4.0)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: posthog>=2.4.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.4.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (3.10.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.24.2)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.39.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.22.2)\n",
      "Requirement already satisfied: pypika>=0.48.9 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.51.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.12/site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (1.78.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.0.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (0.24.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in ./.venv/lib/python3.12/site-packages (from chromadb) (35.0.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in ./.venv/lib/python3.12/site-packages (from chromadb) (5.2.0)\n",
      "Requirement already satisfied: pyproject_hooks in ./.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: cffi>=2.0.0 in ./.venv/lib/python3.12/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.0.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (3.0)\n",
      "Requirement already satisfied: six>=1.9.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in ./.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb) (0.10)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (25.12.19)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (6.33.5)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.12/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.72.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.60b1 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.60b1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation==0.60b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.3)\n",
      "Requirement already satisfied: asgiref~=3.0 in ./.venv/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.60b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.11.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in ./.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in ./.venv/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb) (1.4.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.24.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2026.2.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: shellingham in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in ./.venv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (0.24.0)\n",
      "Requirement already satisfied: rich>=12.3.0 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (14.3.3)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in ./.venv/lib/python3.12/site-packages (from typer>=0.9.0->chromadb) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./.venv/lib/python3.12/site-packages (from rich>=12.3.0->typer>=0.9.0->chromadb) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./.venv/lib/python3.12/site-packages (from rich>=12.3.0->typer>=0.9.0->chromadb) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./.venv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.9.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: httptools>=0.6.3 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.7.1)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
      "Requirement already satisfied: websockets>=10.4 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.12/site-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "\n",
    "!pip install pdfplumber numpy pandas python-dotenv fastapi uvicorn nest-asyncio openai langchain langchain-core langchain-openai langchain-chroma langchain-text-splitters chromadb rank-bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b232ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded.\n",
      "PDFs found: 89\n"
     ]
    }
   ],
   "source": [
    "# import + config\n",
    "\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import json\n",
    "import pdfplumber\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PDF_DIR = Path(\"quilter pdfs - advisor support material\")\n",
    "CHROMA_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"quilter_docs\"\n",
    "\n",
    "print(\"Config loaded.\")\n",
    "print(f\"PDFs found: {len(list(PDF_DIR.glob('*.pdf')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f095981",
   "metadata": {},
   "source": [
    "## PDF Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f7b6a",
   "metadata": {},
   "source": [
    "PDFs are extracted using PDFplumber, chosen for its preservation of block-level layout structure - important for Quilter documents which mix tables, bullet points, and flowing prose. Also Linux, Windows cross compatibility...\n",
    "\n",
    "A boilerplate stripping pass removes recurring noise (page numbers, domain footers) that would otherwise inflate similarity scores between unrelated chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972e8e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 482 pages from 89 PDFs\n"
     ]
    }
   ],
   "source": [
    "# pdf extraction\n",
    "def extract_pages(pdf_path):\n",
    "    pages = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            pages.append({\n",
    "                \"source\": Path(pdf_path).name,\n",
    "                \"page\": i + 1,\n",
    "                \"text\": text.strip()\n",
    "            })\n",
    "    return pages\n",
    "\n",
    "# boiler plate removal\n",
    "def strip_boilerplate(text):\n",
    "    \"\"\"Remove common Quilter header/footer noise.\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned = [\n",
    "        line for line in lines\n",
    "        if not re.match(r'^\\s*\\d+\\s*$', line)  # lone page numbers\n",
    "        and \"quilter.com\" not in line.lower()\n",
    "        and \"quilter plc\" not in line.lower()\n",
    "        and len(line.strip()) > 2\n",
    "    ]\n",
    "    return \"\\n\".join(cleaned)\n",
    "\n",
    "all_pages = []\n",
    "for pdf in sorted(PDF_DIR.glob(\"*.pdf\")):\n",
    "    pages = extract_pages(pdf)\n",
    "    for p in pages:\n",
    "        p[\"text\"] = strip_boilerplate(p[\"text\"])\n",
    "    all_pages.extend(pages)\n",
    "\n",
    "print(f\"Extracted {len(all_pages)} pages from {len(list(PDF_DIR.glob('*.pdf')))} PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c654ff9",
   "metadata": {},
   "source": [
    "## Chunking - Context Aware Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd470d3a",
   "metadata": {},
   "source": [
    "A two-pass context-aware strategy is applied over naive fixed-size splitting when chunking the PDFs.\n",
    "\n",
    "Pass 1 detects section boundaries using structural cues.\n",
    "\n",
    "Pass 2 applies RecursiveCharacterTextSplitter only to sections exceeding 1500 characters, splitting on paragraph breaks first, then if that fails, then sentences, then words.\n",
    "\n",
    "Every chunk is prefixed with its section heading to give the embedding model necessary local context. \n",
    "\n",
    "Each chunk carries an MD5 content hash serving two purposes: deduplication of boilerplate repeated across documents, and incremental re-indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936371f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n",
      "Data-loss while decompressing corrupted data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks before dedup: 1452\n",
      "Total chunks after dedup:  1422\n",
      "Avg chunk length: 885 chars\n"
     ]
    }
   ],
   "source": [
    "def extract_version_from_filename(filename):\n",
    "    match = re.search(r'[_\\-\\s]v(\\d+[\\.\\d]*)', filename, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    match = re.search(r'[_\\-\\s](\\d{4})', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"unknown\"\n",
    "\n",
    "def is_heading(line):\n",
    "    line = line.strip()\n",
    "    if not line or len(line) > 120:\n",
    "        return False\n",
    "    if line.isupper() and len(line) > 3:\n",
    "        return True\n",
    "    if re.match(r'^(\\d+\\.)+\\s+[A-Z]', line):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def split_into_sections(pages):\n",
    "    sections = []\n",
    "    current = {\"heading\": \"Introduction\", \"text\": \"\", \"pages\": [], \"source\": None}\n",
    "    for page in pages:\n",
    "        current[\"source\"] = page[\"source\"]\n",
    "        for line in page[\"text\"].split(\"\\n\"):\n",
    "            if is_heading(line):\n",
    "                if current[\"text\"].strip():\n",
    "                    sections.append(current.copy())\n",
    "                current = {\n",
    "                    \"heading\": line.strip(),\n",
    "                    \"text\": \"\",\n",
    "                    \"pages\": [page[\"page\"]],\n",
    "                    \"source\": page[\"source\"]\n",
    "                }\n",
    "            else:\n",
    "                current[\"text\"] += line + \"\\n\"\n",
    "                if page[\"page\"] not in current[\"pages\"]:\n",
    "                    current[\"pages\"].append(page[\"page\"])\n",
    "    if current[\"text\"].strip():\n",
    "        sections.append(current)\n",
    "    return sections\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    ")\n",
    "\n",
    "def make_chunk(text, source, pages, heading, chunk_index=0):\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"source\": source,\n",
    "        \"pages\": pages,\n",
    "        \"heading\": heading,\n",
    "        \"chunk_index\": chunk_index,\n",
    "        \"content_hash\": hashlib.md5(text.encode()).hexdigest(),\n",
    "        \"doc_version\": extract_version_from_filename(source)\n",
    "    }\n",
    "\n",
    "def chunk_sections(sections):\n",
    "    chunks = []\n",
    "    for section in sections:\n",
    "        full_text = f\"{section['heading']}\\n\\n{section['text']}\".strip()\n",
    "        if len(section[\"text\"]) < 1500:\n",
    "            chunks.append(make_chunk(full_text, section[\"source\"], section[\"pages\"], section[\"heading\"]))\n",
    "        else:\n",
    "            for i, sub in enumerate(splitter.split_text(section[\"text\"])):\n",
    "                sub_text = f\"{section['heading']}\\n\\n{sub}\".strip()\n",
    "                chunks.append(make_chunk(sub_text, section[\"source\"], section[\"pages\"], section[\"heading\"], i))\n",
    "    return chunks\n",
    "\n",
    "# Run it\n",
    "all_chunks = []\n",
    "for pdf in sorted(PDF_DIR.glob(\"*.pdf\")):\n",
    "    pages = extract_pages(pdf)\n",
    "    for p in pages:\n",
    "        p[\"text\"] = strip_boilerplate(p[\"text\"])\n",
    "    sections = split_into_sections(pages)\n",
    "    all_chunks.extend(chunk_sections(sections))\n",
    "\n",
    "# Deduplicate\n",
    "seen = {}\n",
    "deduped_chunks = []\n",
    "for chunk in all_chunks:\n",
    "    if chunk[\"content_hash\"] not in seen:\n",
    "        seen[chunk[\"content_hash\"]] = True\n",
    "        deduped_chunks.append(chunk)\n",
    "\n",
    "print(f\"Total chunks before dedup: {len(all_chunks)}\")\n",
    "print(f\"Total chunks after dedup:  {len(deduped_chunks)}\")\n",
    "print(f\"Avg chunk length: {sum(len(c['text']) for c in deduped_chunks) / len(deduped_chunks):.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb4f1b",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143a397",
   "metadata": {},
   "source": [
    "A simple ChromaDB for a local persistent vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39d2b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 1422 chunks into ChromaDB at ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "texts = [c[\"text\"] for c in deduped_chunks]\n",
    "metadatas = [\n",
    "    {\n",
    "        \"source\": c[\"source\"],\n",
    "        \"pages\": str(c[\"pages\"]),\n",
    "        \"heading\": c[\"heading\"],\n",
    "        \"chunk_index\": c[\"chunk_index\"],\n",
    "        \"content_hash\": c[\"content_hash\"],\n",
    "        \"doc_version\": c[\"doc_version\"]\n",
    "    }\n",
    "    for c in deduped_chunks\n",
    "]\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embeddings,\n",
    "    metadatas=metadatas,\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n",
    "print(f\"Indexed {len(texts)} chunks into ChromaDB at {CHROMA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ce10d",
   "metadata": {},
   "source": [
    "## Retrieval - Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268e7be",
   "metadata": {},
   "source": [
    "Combination of dense vector search with sparse BM25. Results are merged using RFF rewarding documents ranked highly by both retrievers. Retrieval count defaults to a fixed k=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b017ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever ready.\n"
     ]
    }
   ],
   "source": [
    "# BM25 sparse retriever\n",
    "tokenized_corpus = [c[\"text\"].lower().split() for c in deduped_chunks]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "\n",
    "def hybrid_retrieve(query, k=6):\n",
    "    \"\"\"Combine dense (ChromaDB) and sparse (BM25) retrieval with RRF.\"\"\"\n",
    "    \n",
    "    # Dense retrieval\n",
    "    dense_results = vectorstore.similarity_search_with_score(query, k=k*2)\n",
    "    dense_ranked = {r[0].page_content: i for i, r in enumerate(dense_results)}\n",
    "    \n",
    "    # Sparse BM25 retrieval\n",
    "    tokenized_query = query.lower().split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:k*2]\n",
    "    bm25_ranked = {deduped_chunks[i][\"text\"]: rank for rank, i in enumerate(bm25_top_indices)}\n",
    "    \n",
    "    # Reciprocal Rank Fusion\n",
    "    all_texts = set(dense_ranked.keys()) | set(bm25_ranked.keys())\n",
    "    rrf_scores = {}\n",
    "    for text in all_texts:\n",
    "        dense_rank = dense_ranked.get(text, k*2)\n",
    "        bm25_rank = bm25_ranked.get(text, k*2)\n",
    "        rrf_scores[text] = 1/(60 + dense_rank) + 1/(60 + bm25_rank)\n",
    "    \n",
    "    top_texts = sorted(rrf_scores, key=rrf_scores.get, reverse=True)[:k]\n",
    "    \n",
    "    # Fetch full chunk metadata for top results\n",
    "    results = []\n",
    "    text_to_chunk = {c[\"text\"]: c for c in deduped_chunks}\n",
    "    for text in top_texts:\n",
    "        if text in text_to_chunk:\n",
    "            results.append(text_to_chunk[text])\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "print(\"Hybrid retriever ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5852c67",
   "metadata": {},
   "source": [
    "## Answer Generation &  Guardrail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcada3f",
   "metadata": {},
   "source": [
    "Strict prompt, temperature at 0, fallback can be triggered with the first response or via checkfaithfulness gaurdrail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c798afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer generation ready.\n"
     ]
    }
   ],
   "source": [
    "# answer generation with guardrails\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an assistant that helps Quilter financial advisers answer operational questions.\n",
    "\n",
    "STRICT RULES:\n",
    "1. Answer ONLY using the context provided below. Do not use any outside knowledge.\n",
    "2. If the context does not contain enough information to answer the question, respond with exactly:\n",
    "   \"Please reach out to the Contact Centre.\"\n",
    "3. Always cite your sources using the format [Source: filename, p.X] at the end of each point.\n",
    "4. Do not give financial advice. Only explain processes and operational steps.\n",
    "5. Be concise and structured. Use bullet points for multi-step processes.\n",
    "\"\"\"\n",
    "\n",
    "def check_faithfulness(answer, context_texts):\n",
    "    \"\"\"Ask GPT to verify the answer is grounded in the context.\"\"\"\n",
    "    context_combined = \"\\n\\n\".join(context_texts[:4])\n",
    "    check_prompt = f\"\"\"Given this context:\n",
    "{context_combined}\n",
    "\n",
    "And this answer:\n",
    "{answer}\n",
    "\n",
    "Does every factual claim in the answer appear in the context? \n",
    "Reply with JSON only: {{\"faithful\": true/false, \"reason\": \"brief explanation\"}}\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # cheaper model for this check\n",
    "        messages=[{\"role\": \"user\", \"content\": check_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return {\"faithful\": True, \"reason\": \"Could not parse faithfulness check\"}\n",
    "\n",
    "\n",
    "def answer_query(query, k=6, check_grounding=True):\n",
    "    # Retrieve relevant chunks\n",
    "    retrieved = hybrid_retrieve(query, k=k)\n",
    "    \n",
    "    if not retrieved:\n",
    "        return {\n",
    "            \"answer\": \"Please reach out to the Contact Centre.\",\n",
    "            \"sources\": [],\n",
    "            \"faithful\": None,\n",
    "            \"chunks_used\": 0\n",
    "        }\n",
    "    \n",
    "    # Build context string\n",
    "    context_parts = []\n",
    "    for chunk in retrieved:\n",
    "        source_label = f\"[Source: {chunk['source']}, p.{chunk['pages']}]\"\n",
    "        context_parts.append(f\"{source_label}\\n{chunk['text']}\")\n",
    "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Generate answer\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    # Faithfulness check\n",
    "    faithfulness = None\n",
    "    if check_grounding:\n",
    "        faithfulness = check_faithfulness(answer, [c[\"text\"] for c in retrieved])\n",
    "        if not faithfulness[\"faithful\"]:\n",
    "            answer = \"Please reach out to the Contact Centre.\"\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": [{\"source\": c[\"source\"], \"pages\": c[\"pages\"], \"heading\": c[\"heading\"]} for c in retrieved],\n",
    "        \"faithful\": faithfulness,\n",
    "        \"chunks_used\": len(retrieved)\n",
    "    }\n",
    "\n",
    "    \n",
    "print(\"Answer generation ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8aec8",
   "metadata": {},
   "source": [
    "## Local FastAPI Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbef87e",
   "metadata": {},
   "source": [
    "Two routes are provided: /health for server status and /ask for query submission, with configurable parameters for retrieval depth and guardrail toggling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12883e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastAPI running at http://localhost:8000\n",
      "Docs at http://localhost:8000/docs\n"
     ]
    }
   ],
   "source": [
    "# FastAPI app\n",
    "\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "import threading\n",
    "\n",
    "nest_asyncio.apply()  # allows FastAPI to run inside a Jupyter notebook\n",
    "\n",
    "app = FastAPI(title=\"Quilter Advisor Assistant\")\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    k: int = 6\n",
    "    check_grounding: bool = True\n",
    "\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    answer: str\n",
    "    sources: list\n",
    "    faithful: dict | None\n",
    "    chunks_used: int\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\", \"chunks_indexed\": len(deduped_chunks)}\n",
    "\n",
    "@app.post(\"/ask\", response_model=QueryResponse)\n",
    "def ask(request: QueryRequest):\n",
    "    result = answer_query(request.query, k=request.k, check_grounding=request.check_grounding)\n",
    "    return result\n",
    "\n",
    "\n",
    "def run_server():\n",
    "    import asyncio\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"warning\", loop=\"asyncio\")\n",
    "    server = uvicorn.Server(config)\n",
    "    loop.run_until_complete(server.serve())\n",
    "\n",
    "thread = threading.Thread(target=run_server, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "print(\"FastAPI running at http://localhost:8000\")\n",
    "print(\"Docs at http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5adb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is up: {'status': 'ok', 'chunks_indexed': 1422}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(2)  # give the thread a moment to start\n",
    "\n",
    "import requests\n",
    "try:\n",
    "    r = requests.get(\"http://localhost:8000/health\", timeout=3)\n",
    "    print(\"Server is up:\", r.json())\n",
    "except Exception as e:\n",
    "    print(\"Server not running:\", e)\n",
    "    print(\"\\nCheck that Cell 8 ran without errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb880a",
   "metadata": {},
   "source": [
    "Test a single question and answer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddf94f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'chunks_indexed': 1422}\n",
      "\n",
      "=== ANSWER ===\n",
      "- If the deceased’s ISA was held with Quilter and you wish to transfer the APS allowance to another ISA manager, you need to:\n",
      "  - Contact your preferred ISA manager who will instruct Quilter to transfer the allowance.\n",
      "  - Use the other ISA manager’s form for authorising an APS allowance transfer.\n",
      "  - Ensure that you have not already subscribed towards that allowance with Quilter.\n",
      "  - Note that the APS allowance can only be transferred once and the transfer cannot be reversed.\n",
      "  - Understand that once the allowance is transferred, subscriptions may only be made in cash with the new ISA manager.\n",
      "  - Be aware that it is not possible to cancel the transfer once Quilter has returned the new ISA manager’s form to them. [Source: 18152-isa-aps-options--for-deaths-before-6-april-2018.pdf, p.2]\n",
      "\n",
      "- If the deceased’s ISA was held with another ISA manager, you need to:\n",
      "  - Liaise with the deceased’s ISA manager to transfer the allowance to a different ISA manager. [Source: 18051-isa-aps-options-after-6-april.pdf, p.3]\n",
      "\n",
      "=== SOURCES ===\n",
      "  - 18152-isa-aps-options--for-deaths-before-6-april-2018.pdf | Introduction | pp.[1]\n",
      "  - 18152-isa-aps-options--for-deaths-before-6-april-2018.pdf | 1. If the deceased’s ISA was held with Quilter, the APS options are: | pp.[2]\n",
      "  - accepting_documentation_via_email_and_prompt.pdf | Introduction | pp.[1, 2, 3]\n",
      "  - 18051-isa-aps-options-after-6-april.pdf | Introduction | pp.[1]\n",
      "  - 18051-isa-aps-options-after-6-april.pdf | 1. If the deceased’s ISA was held with Quilter, the APS options are: | pp.[2]\n",
      "  - 18051-isa-aps-options-after-6-april.pdf | 2. If the deceased had an ISA with another ISA manager, the options are: | pp.[3]\n",
      "\n",
      "=== GROUNDING CHECK ===\n",
      "{'faithful': True, 'reason': 'All factual claims in the answer are supported by the context provided, including the steps for transferring the APS allowance and the conditions that apply.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Test the health endpoint\n",
    "print(requests.get(\"http://localhost:8000/health\").json())\n",
    "\n",
    "# Test a query\n",
    "response = requests.post(\"http://localhost:8000/ask\", json={\n",
    "    \"query\": \"What are the requirements to complete an ISA transfer?\",\n",
    "    \"k\": 6,\n",
    "    \"check_grounding\": True\n",
    "})\n",
    "\n",
    "result = response.json()\n",
    "print(\"\\n=== ANSWER ===\")\n",
    "print(result[\"answer\"])\n",
    "print(\"\\n=== SOURCES ===\")\n",
    "for s in result[\"sources\"]:\n",
    "    print(f\"  - {s['source']} | {s['heading']} | pp.{s['pages']}\")\n",
    "print(\"\\n=== GROUNDING CHECK ===\")\n",
    "print(result[\"faithful\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb072536",
   "metadata": {},
   "source": [
    "# Offline Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452aeb5a",
   "metadata": {},
   "source": [
    "## Annotated Evaluation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08d4eb",
   "metadata": {},
   "source": [
    "11 manually created Question answer pairs with source documentation and location within the source.\n",
    "5 out of scope questions specifically for refusal rate testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0bbadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SET = [\n",
    "    {\n",
    "        \"question\": \"What is Quilter's Absolute Trust?\",\n",
    "        \"expected_answer\": \"A simple IHT solution where the client does not require access to the capital, knows who they want to leave their wealth to, and requires no future flexibility.\",\n",
    "        \"source_pdf\": \"20881-understanding-our-range-of-trusts.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When is Life Fund Tax Charge Taken?\",\n",
    "        \"expected_answer\": \"The charge is taken at numerous points through the year.\",\n",
    "        \"source_pdf\": \"7910-taxation-for-quilter-life-funds.pdf\",\n",
    "        \"source_pages\": [4],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is the Quilter Smoothed Balanced Fund (Standard Life) a suitable choice for?\",\n",
    "        \"expected_answer\": \"The funds may be suitable for an investor who is approaching or is in retirement, wants to reduce day-to-day fluctuations, is looking to potentially grow their investment, is willing to accept some risk, intends to invest for at least five years, wants to take an income, and has a financial adviser.\",\n",
    "        \"source_pdf\": \"kiid-gb00bt9lzb27-en-gb.pdf\",\n",
    "        \"source_pages\": [2],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are investment pathways?\",\n",
    "        \"expected_answer\": \"Instead of having to choose an investment for your drawdown pot, you choose from four options that closely match what you would like to do with your money in the next 5 years.\",\n",
    "        \"source_pdf\": \"20993-what-you-need-to-know-about-investment-pathways.pdf\",\n",
    "        \"source_pages\": [3],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are share identification rules?\",\n",
    "        \"expected_answer\": \"Rules that ended bed and breakfasting by matching disposed units first with units acquired the same day, then units acquired in the following 30 days, then units in the Section 104 holding.\",\n",
    "        \"source_pdf\": \"20720-cgt-quick-reference-guide-3-share-identification-rules.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In the Legal Framework what is point 6.1.2?\",\n",
    "        \"expected_answer\": \"The Intermediary will be responsible for ensuring that only permitted individuals access and use the Services, and will be liable for any acts or omissions resulting from use of User Access by any of its Users.\",\n",
    "        \"source_pdf\": \"7161_legal_framework.pdf\",\n",
    "        \"source_pages\": [3],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In the Legal Framework, what is the policy on Third Party suppliers?\",\n",
    "        \"expected_answer\": \"Third party providers may require an Intermediary or User to agree to additional terms for use of their software or services, without prejudice to the obligations of the Parties under the Agreement.\",\n",
    "        \"source_pdf\": \"7161_legal_framework.pdf\",\n",
    "        \"source_pages\": [5],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an Additional Permitted Subscription (APS)?\",\n",
    "        \"expected_answer\": \"When an ISA investor dies on or after 3 December 2014, a surviving spouse is entitled to invest into an ISA over and above the annual ISA allowance, known as an Additional Permitted Subscription or APS.\",\n",
    "        \"source_pdf\": \"18152-isa-aps-options--for-deaths-before-6-april-2018.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can you complete the Intermediary Resignation Form?\",\n",
    "        \"expected_answer\": \"Either electronically by saving and opening in Adobe Acrobat to complete editable fields then signing, or by hand by printing and completing in block capitals using blue or black ink.\",\n",
    "        \"source_pdf\": \"19502-intermediary-registration-form.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the objectives of the WealthSelect Sustainable Portfolios?\",\n",
    "        \"expected_answer\": \"To achieve capital growth over five or more years whilst supporting sustainable solutions to environmental and social challenges aligned with UN Sustainable Development Goals, managing ESG risks and maintaining a smaller carbon footprint than the MSCI ACWI reference index.\",\n",
    "        \"source_pdf\": \"11541_wealthselect_due_dilligence.pdf\",\n",
    "        \"source_pages\": [5],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is reason number 1 for using onshore bonds?\",\n",
    "        \"expected_answer\": \"Tax deferral and control — clients are only assessable for tax when a chargeable event occurs, such as withdrawals over the 5% allowance, meaning they control when they report and pay tax.\",\n",
    "        \"source_pdf\": \"23416_six_reasons_why.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can I make money from Bitcoin?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the weather doing?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is Kai Glahome?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I increase my expected returns?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where is London?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b98275",
   "metadata": {},
   "source": [
    "## Running Offline Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b366da",
   "metadata": {},
   "source": [
    "Offline Evaluation Metrics\n",
    "\n",
    "Subcategorised into retrieval, generation, and system... Discussed in the documentation why.\n",
    "\n",
    "**Retrieval** (first 3 derived from Recall@6)\n",
    "\n",
    "- **Source PDF Recall@6** — For each in-scope question, checks whether the correct source document appeared within the top 6 retrieved chunks. A score of 1.0 indicates perfect retrieval coverage.\n",
    "- **Page Recall@6** — For each in-scope question, checks whether the correct page appeared within the top 6 retrieved chunks. A score of 1.0 indicates perfect page-level retrieval coverage.\n",
    "- **Avg Source Rank** — Where the correct document was retrieved, records its position in the results list. Lower is better — a rank of 1 means the correct document was the top result.\n",
    "- **Avg Redundancy Score** — Measures the proportion of retrieved chunks that came from distinct source documents. A score of 1.0 means all 6 chunks came from different documents; a lower score indicates multiple chunks from the same source.\n",
    "\n",
    "**Generation**\n",
    "\n",
    "- **Avg Correctness Score (LLM Judge)** — GPT-4o-mini judges each generated answer against the hand-crafted expected answer on a 1-3 scale: 1 = incorrect, 2 = partially correct, 3 = correct and complete.\n",
    "- **Avg Groundedness Score (LLM Judge)** — A separate LLM judge assesses whether the generated answer is grounded in the retrieved sources rather than outside knowledge, on a 1-3 scale.\n",
    "\n",
    "**System**\n",
    "\n",
    "- **Faithful Answers (LLM Judge)** — Count of in-scope answers that passed the inference-time faithfulness check. Failed answers are suppressed and replaced with the Contact Centre fallback.\n",
    "- **Refusal Accuracy** — Proportion of out-of-scope questions correctly deflected to the Contact Centre fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba42ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "def run_offline_evaluation(eval_set):\n",
    "    results = []\n",
    "    \n",
    "    for item in eval_set:\n",
    "        response = requests.post(\"http://localhost:8000/ask\", json={\n",
    "            \"query\": item[\"question\"],\n",
    "            \"k\": 6,\n",
    "            \"check_grounding\": True\n",
    "        })\n",
    "        result = response.json()\n",
    "        \n",
    "        answer = result[\"answer\"]\n",
    "        sources = result[\"sources\"]\n",
    "        faithful = result[\"faithful\"]\n",
    "        retrieved_pdfs = [s[\"source\"] for s in sources]\n",
    "        retrieved_pages = [p for s in sources for p in (eval(s[\"pages\"]) if isinstance(s[\"pages\"], str) else s[\"pages\"])]\n",
    "        \n",
    "        # --- Retrieval check (in-scope only) ---\n",
    "        source_hit = None\n",
    "        source_rank = None\n",
    "        page_hit = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            source_hit = item[\"source_pdf\"] in retrieved_pdfs\n",
    "            if source_hit:\n",
    "                source_rank = next(i+1 for i, pdf in enumerate(retrieved_pdfs) if pdf == item[\"source_pdf\"])\n",
    "            page_hit = any(p in retrieved_pages for p in item[\"source_pages\"])\n",
    "\n",
    "        # --- Retrieval redundancy (in-scope only) ---\n",
    "        redundancy_score = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            distinct_pdfs = len(set(retrieved_pdfs))\n",
    "            redundancy_score = round(distinct_pdfs / len(retrieved_pdfs), 2)\n",
    "\n",
    "        # --- Refusal check (out-of-scope only) ---\n",
    "        correctly_refused = None\n",
    "        if item[\"type\"] == \"out-of-scope\":\n",
    "            correctly_refused = \"contact centre\" in answer.lower()\n",
    "\n",
    "        # --- LLM-as-judge answer correctness (in-scope only) ---\n",
    "        llm_score = None\n",
    "        llm_reasoning = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            judge_prompt = f\"\"\"You are evaluating an AI assistant's answer against a known correct answer.\n",
    "\n",
    "Question: {item[\"question\"]}\n",
    "Expected Answer: {item[\"expected_answer\"]}\n",
    "Generated Answer: {answer}\n",
    "\n",
    "Score the generated answer on a scale of 1-3:\n",
    "1 = Incorrect or missing key information\n",
    "2 = Partially correct, captures some but not all key points\n",
    "3 = Correct and complete\n",
    "\n",
    "Respond with JSON only: {{\"score\": <1-3>, \"reasoning\": \"<brief explanation>\"}}\"\"\"\n",
    "\n",
    "            judge_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    "                temperature=0\n",
    "            )\n",
    "            try:\n",
    "                judge_result = json.loads(judge_response.choices[0].message.content)\n",
    "                llm_score = judge_result[\"score\"]\n",
    "                llm_reasoning = judge_result[\"reasoning\"]\n",
    "            except:\n",
    "                llm_score = None\n",
    "                llm_reasoning = \"Parse error\"\n",
    "\n",
    "        # --- LLM-as-judge groundedness (in-scope only) ---\n",
    "        groundedness_score = None\n",
    "        groundedness_reasoning = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            groundedness_prompt = f\"\"\"You are evaluating whether an AI assistant's answer is grounded in the retrieved documents.\n",
    "\n",
    "Retrieved Sources: {[s['source'] for s in sources]}\n",
    "Generated Answer: {answer}\n",
    "\n",
    "Does the answer contain only information that could plausibly come from the retrieved sources, or does it appear to include invented or outside knowledge?\n",
    "\n",
    "Score on a scale of 1-3:\n",
    "1 = Answer contains claims not supported by retrieved sources\n",
    "2 = Answer is mostly grounded but contains some unsupported claims\n",
    "3 = Answer is fully grounded in the retrieved sources\n",
    "\n",
    "Respond with JSON only: {{\"score\": <1-3>, \"reasoning\": \"<brief explanation>\"}}\"\"\"\n",
    "\n",
    "            groundedness_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": groundedness_prompt}],\n",
    "                temperature=0\n",
    "            )\n",
    "            try:\n",
    "                groundedness_result = json.loads(groundedness_response.choices[0].message.content)\n",
    "                groundedness_score = groundedness_result[\"score\"]\n",
    "                groundedness_reasoning = groundedness_result[\"reasoning\"]\n",
    "            except:\n",
    "                groundedness_score = None\n",
    "                groundedness_reasoning = \"Parse error\"\n",
    "\n",
    "        results.append({\n",
    "            \"question\": item[\"question\"],\n",
    "            \"type\": item[\"type\"],\n",
    "            \"answer_preview\": answer[:200],\n",
    "            \"source_hit\": source_hit,\n",
    "            \"source_rank\": source_rank,\n",
    "            \"page_hit\": page_hit,\n",
    "            \"redundancy_score\": redundancy_score,\n",
    "            \"correctly_refused\": correctly_refused,\n",
    "            \"llm_score\": llm_score,\n",
    "            \"llm_reasoning\": llm_reasoning,\n",
    "            \"groundedness_score\": groundedness_score,\n",
    "            \"groundedness_reasoning\": groundedness_reasoning,\n",
    "            \"faithful\": faithful\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86c29c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it\n",
    "results = run_offline_evaluation(EVAL_SET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80d58e",
   "metadata": {},
   "source": [
    "## Results and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d757ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_evaluation_report(results):\n",
    "    in_scope = [r for r in results if r[\"type\"] == \"in-scope\"]\n",
    "    out_scope = [r for r in results if r[\"type\"] == \"out-of-scope\"]\n",
    "\n",
    "    # Compute metrics\n",
    "    recall = sum(1 for r in in_scope if r[\"source_hit\"]) / len(in_scope)\n",
    "    avg_rank = sum(r[\"source_rank\"] for r in in_scope if r[\"source_rank\"]) / max(sum(1 for r in in_scope if r[\"source_rank\"]), 1)\n",
    "    page_recall = sum(1 for r in in_scope if r[\"page_hit\"]) / len(in_scope)\n",
    "    avg_redundancy = sum(r[\"redundancy_score\"] for r in in_scope if r[\"redundancy_score\"] is not None) / len(in_scope)\n",
    "    scored = [r for r in in_scope if r[\"llm_score\"]]\n",
    "    avg_llm_score = sum(r[\"llm_score\"] for r in scored) / max(len(scored), 1)\n",
    "    scored_grounded = [r for r in in_scope if r[\"groundedness_score\"]]\n",
    "    avg_groundedness = sum(r[\"groundedness_score\"] for r in scored_grounded) / max(len(scored_grounded), 1)\n",
    "    faithful_count = sum(1 for r in in_scope if r[\"faithful\"] and r[\"faithful\"].get(\"faithful\"))\n",
    "    refusal_accuracy = sum(1 for r in out_scope if r[\"correctly_refused\"]) / len(out_scope)\n",
    "\n",
    "    # Summary table\n",
    "    print(\"=\" * 60)\n",
    "    print(\"OFFLINE EVALUATION REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    summary_data = {\n",
    "        \"Metric\": [\n",
    "            \"Source PDF Recall@6\",\n",
    "            \"Page Recall@6\",\n",
    "            \"Avg Source Rank (lower = better)\",\n",
    "            \"Avg Redundancy Score (1.0 = fully diverse)\",\n",
    "            \"Avg Correctness Score (LLM Judge) /3\",\n",
    "            \"Avg Groundedness Score (LLM Judge) /3\",\n",
    "            f\"Faithful Answers\",\n",
    "            \"Refusal Accuracy (out-of-scope)\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            f\"{recall:.2f}\",\n",
    "            f\"{page_recall:.2f}\",\n",
    "            f\"{avg_rank:.1f}\",\n",
    "            f\"{avg_redundancy:.2f}\",\n",
    "            f\"{avg_llm_score:.2f}\",\n",
    "            f\"{avg_groundedness:.2f}\",\n",
    "            f\"{faithful_count}/{len(in_scope)}\",\n",
    "            f\"{refusal_accuracy:.2f}\"\n",
    "        ]\n",
    "    }\n",
    "    print(pd.DataFrame(summary_data).to_string(index=False))\n",
    "\n",
    "    # Per question breakdown\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PER QUESTION BREAKDOWN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for r in results:\n",
    "        print(f\"\\n{'─' * 60}\")\n",
    "        print(f\"Q:  {r['question'][:80]}\")\n",
    "        print(f\"    Type: {r['type'].upper()}\")\n",
    "        if r[\"type\"] == \"in-scope\":\n",
    "            print(f\"    Source Hit:   {'✓' if r['source_hit'] else '✗'} (rank {r['source_rank']})\")\n",
    "            print(f\"    Page Hit:     {'✓' if r['page_hit'] else '✗'}\")\n",
    "            print(f\"    Redundancy:   {r['redundancy_score']}\")\n",
    "            print(f\"    Correctness:  {r['llm_score']}/3 — {r['llm_reasoning']}\")\n",
    "            print(f\"    Groundedness: {r['groundedness_score']}/3 — {r['groundedness_reasoning']}\")\n",
    "            print(f\"    Faithful:     {'✓' if r['faithful'] and r['faithful'].get('faithful') else '✗'}\")\n",
    "        else:\n",
    "            print(f\"    Refused:      {'✓' if r['correctly_refused'] else '✗'}\")\n",
    "        print(f\"    Preview:      {r['answer_preview'][:150]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db6b3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OFFLINE EVALUATION REPORT\n",
      "============================================================\n",
      "                                    Metric Value\n",
      "                       Source PDF Recall@6  0.91\n",
      "                             Page Recall@6  0.91\n",
      "          Avg Source Rank (lower = better)   1.3\n",
      "Avg Redundancy Score (1.0 = fully diverse)  0.47\n",
      "      Avg Correctness Score (LLM Judge) /3  2.09\n",
      "     Avg Groundedness Score (LLM Judge) /3  2.45\n",
      "                          Faithful Answers  8/11\n",
      "           Refusal Accuracy (out-of-scope)  0.80\n",
      "\n",
      "============================================================\n",
      "PER QUESTION BREAKDOWN\n",
      "============================================================\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  What is Quilter's Absolute Trust?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✗ (rank None)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   1.0\n",
      "    Correctness:  1/3 — The generated answer does not provide any information about Quilter's Absolute Trust and instead directs the user to contact a center, missing all key points of the expected answer.\n",
      "    Groundedness: 1/3 — The answer 'Please reach out to the Contact Centre' does not appear to be supported by any of the retrieved documents, which focus on specific topics related to trusts, taxation, and investment bonds. There is no indication in the sources that suggests contacting a center is relevant or mentioned.\n",
      "    Faithful:     ✗\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  When is Life Fund Tax Charge Taken?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.17\n",
      "    Correctness:  3/3 — The generated answer correctly states that the Life Fund Tax Charge is taken at numerous points throughout the year and provides detailed explanations of when the charge is applied, aligning with the expected answer.\n",
      "    Groundedness: 3/3 — The generated answer accurately reflects the information regarding the Life Fund Tax Charge as described in the retrieved document, including the various points at which the charge is applied and the specific circumstances under which it is deducted.\n",
      "    Faithful:     ✓\n",
      "    Preview:      - The Life Fund Tax Charge is taken at numerous points throughout the year.\n",
      "- It is applied during income distributions when a cash distribution is al\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  Who is the Quilter Smoothed Balanced Fund (Standard Life) a suitable choice for?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.33\n",
      "    Correctness:  3/3 — The generated answer accurately captures all the key points from the expected answer, providing a complete and correct description of who the Quilter Smoothed Balanced Fund is suitable for.\n",
      "    Groundedness: 3/3 — The generated answer lists criteria for the suitability of the Quilter Smoothed Balanced Fund, which aligns with the information found in the retrieved source (kiid-gb00bt9lzb27-en-gb.pdf, p.3). All points mentioned are plausible and relevant to the context of the fund.\n",
      "    Faithful:     ✓\n",
      "    Preview:      The Quilter Smoothed Balanced Fund (Standard Life) may be suitable for an investor who:\n",
      "\n",
      "- Is approaching or is in retirement.\n",
      "- Wants to reduce the s\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  What are investment pathways?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.33\n",
      "    Correctness:  2/3 — The generated answer captures the essence of investment pathways and their purpose, but it does not explicitly mention the aspect of choosing from four options that align with individual preferences for the next 5 years, which is a key part of the expected answer.\n",
      "    Groundedness: 3/3 — The answer accurately describes investment pathways as options for individuals to choose investment funds for their pension drawdown, and it correctly references the requirement by the Financial Conduct Authority (FCA) for these pathways to be offered as non-advised options. This information is consistent with the content expected in the retrieved document '20993-what-you-need-to-know-about-investment-pathways.pdf'.\n",
      "    Faithful:     ✓\n",
      "    Preview:      - Investment pathways are options provided to help individuals choose investment funds for their drawdown pot when taking money from their pension. Th\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  What are share identification rules?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   1.0\n",
      "    Correctness:  2/3 — The generated answer captures the essence of share identification rules and mentions their role in preventing bed and breakfasting, but it does not explicitly detail the specific matching process outlined in the expected answer.\n",
      "    Groundedness: 3/3 — The answer is fully grounded in the retrieved sources, specifically referencing the share identification rules and their historical context as described in the document '20720-cgt-quick-reference-guide-3-share-identification-rules.pdf'.\n",
      "    Faithful:     ✓\n",
      "    Preview:      - Share identification rules are used to calculate the Capital Gains realised on the disposal of shares or units in a collective investment scheme. Th\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  In the Legal Framework what is point 6.1.2?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✗\n",
      "    Redundancy:   0.17\n",
      "    Correctness:  1/3 — The generated answer does not address the question and fails to provide any relevant information about point 6.1.2.\n",
      "    Groundedness: 1/3 — The answer 'Please reach out to the Contact Centre' does not appear to be supported by the retrieved legal framework documents, which likely contain specific legal information rather than contact instructions.\n",
      "    Faithful:     ✗\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  In the Legal Framework, what is the policy on Third Party suppliers?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.17\n",
      "    Correctness:  3/3 — The generated answer accurately captures all key points from the expected answer, including the requirement for additional terms from third-party providers and the stipulation that these terms do not affect the obligations under the Agreement.\n",
      "    Groundedness: 3/3 — The generated answer accurately reflects the content that could plausibly be found in a legal framework document, specifically discussing third-party providers and additional terms, which aligns with typical legal language and concepts.\n",
      "    Faithful:     ✓\n",
      "    Preview:      - The policy acknowledges that certain third-party providers of ancillary software or services, which may be used by the Provider, the Intermediary, a\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  What is an Additional Permitted Subscription (APS)?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 2)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.33\n",
      "    Correctness:  3/3 — The generated answer accurately defines an Additional Permitted Subscription (APS) and includes all key points from the expected answer, including the context of a surviving spouse or civil partner and the relevant date.\n",
      "    Groundedness: 3/3 — The answer accurately describes the concept of an Additional Permitted Subscription (APS) and its relevance to surviving spouses or civil partners, which is consistent with the information provided in the retrieved sources.\n",
      "    Faithful:     ✓\n",
      "    Preview:      - An Additional Permitted Subscription (APS) is an allowance that enables a surviving spouse or civil partner to invest in an ISA over and above the a\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  How can you complete the Intermediary Resignation Form?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.67\n",
      "    Correctness:  2/3 — The generated answer captures the main methods for completing the form (electronically and by hand) and provides additional details about submission methods and date format. However, it includes extra information (like the letterhead requirement) that was not part of the expected answer, and it does not explicitly mention the signing process as required in the expected answer.\n",
      "    Groundedness: 3/3 — The answer provides detailed instructions on completing and submitting the intermediary registration form, which aligns with the content expected in the retrieved document '19502-intermediary-registration-form.pdf'. All points mentioned, including electronic and hand completion methods, date format, additional requirements, and submission methods, are plausible and consistent with the type of information typically found in such forms.\n",
      "    Faithful:     ✓\n",
      "    Preview:      - **Option 1 (Electronic Completion):**\n",
      "  - Save the form to your desktop.\n",
      "  - Open it in Adobe Acrobat to complete the editable fields.\n",
      "  - Either pr\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  What are the objectives of the WealthSelect Sustainable Portfolios?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 1)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.33\n",
      "    Correctness:  2/3 — The generated answer captures the objective of achieving capital growth over five years or more but omits key details about supporting sustainable solutions, managing ESG risks, and maintaining a smaller carbon footprint.\n",
      "    Groundedness: 3/3 — The answer is fully grounded in the retrieved source, specifically referencing the WealthSelect Sustainable Portfolios and their aim for capital growth over a specified period, which aligns with the content expected in the provided document.\n",
      "    Faithful:     ✓\n",
      "    Preview:      - The WealthSelect Sustainable Portfolios aim to achieve capital growth over a period of five years or more. [Source: 11541_wealthselect_due_dilligenc\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  What is reason number 1 for using onshore bonds?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   ✓ (rank 3)\n",
      "    Page Hit:     ✓\n",
      "    Redundancy:   0.67\n",
      "    Correctness:  1/3 — The generated answer does not address the question about the reason for using onshore bonds and instead suggests contacting a support center, missing the key information about tax deferral and control.\n",
      "    Groundedness: 1/3 — The answer 'Please reach out to the Contact Centre' does not appear to be supported by any of the retrieved documents, which focus on onshore bonds and related financial topics. There is no indication in the sources that suggests contacting a center is relevant or mentioned.\n",
      "    Faithful:     ✗\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  How can I make money from Bitcoin?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      ✓\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  What is the weather doing?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      ✓\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  Who is Kai Glahome?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      ✓\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  How do I increase my expected returns?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      ✗\n",
      "    Preview:      - If you could increase your chances of improving your returns by taking more risk, you have several options:\n",
      "  - Be willing to take more risk with al\n",
      "\n",
      "────────────────────────────────────────────────────────────\n",
      "Q:  Where is London?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      ✓\n",
      "    Preview:      Please reach out to the Contact Centre.\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_report(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
