{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b936d810",
   "metadata": {},
   "source": [
    "# Quilter Senior AI Scientist Challenge â€“ Advisor Assistant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2156477",
   "metadata": {},
   "source": [
    "Kai Glahome\n",
    "21/02/2026\n",
    "\n",
    "Design decisions, evaluation strategy, and reflections on further improvements are covered in the accompanying documentation.\n",
    "\n",
    "\n",
    "To run:\n",
    "\n",
    "- Place the source Quilter PDF documents in a folder named `quilter_pdfs_advisor_support_material` at the project root.\n",
    "- Add your OpenAI API key in a `.env` file at the project root:  \n",
    "  `OPENAI_API_KEY=your_api_key_here`\n",
    "- Run the notebook from the start. The notebook will:\n",
    "  - Ingest and process the PDFs\n",
    "  - Build the Chroma vector database automatically\n",
    "  - Provide the interactive assistant interface\n",
    "\n",
    "I ran on Python 3.12.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6513b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-doc==0.0.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.0.4)\n",
      "Requirement already satisfied: annotated-types==0.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: anyio==4.12.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (4.12.1)\n",
      "Requirement already satisfied: asttokens==3.0.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: attrs==25.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (25.4.0)\n",
      "Requirement already satisfied: backoff==2.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.2.1)\n",
      "Requirement already satisfied: bcrypt==5.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: beautifulsoup4==4.14.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (4.14.3)\n",
      "Requirement already satisfied: build==1.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (1.4.0)\n",
      "Requirement already satisfied: certifi==2026.1.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (2026.1.4)\n",
      "Requirement already satisfied: charset-normalizer==3.4.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (3.4.4)\n",
      "Requirement already satisfied: chromadb==1.5.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: click==8.3.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (8.3.1)\n",
      "Requirement already satisfied: comm==0.2.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (0.2.3)\n",
      "Requirement already satisfied: debugpy==1.8.20 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (1.8.20)\n",
      "Requirement already satisfied: decorator==5.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (5.2.1)\n",
      "Requirement already satisfied: distro==1.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (1.9.0)\n",
      "Requirement already satisfied: durationpy==0.10 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (0.10)\n",
      "Requirement already satisfied: executing==2.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (2.2.1)\n",
      "Requirement already satisfied: fastapi==0.129.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (0.129.0)\n",
      "Requirement already satisfied: fastjsonschema==2.21.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (2.21.2)\n",
      "Requirement already satisfied: filelock==3.24.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (3.24.3)\n",
      "Requirement already satisfied: flatbuffers==25.12.19 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (25.12.19)\n",
      "Requirement already satisfied: fsspec==2026.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (2026.2.0)\n",
      "Requirement already satisfied: googleapis-common-protos==1.72.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (1.72.0)\n",
      "Requirement already satisfied: grpcio==1.78.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (1.78.0)\n",
      "Requirement already satisfied: h11==0.16.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (0.16.0)\n",
      "Requirement already satisfied: httpcore==1.0.9 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (1.0.9)\n",
      "Requirement already satisfied: httptools==0.7.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (0.7.1)\n",
      "Requirement already satisfied: httpx==0.28.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (0.28.1)\n",
      "Requirement already satisfied: huggingface_hub==1.4.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (1.4.1)\n",
      "Requirement already satisfied: idna==3.11 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (3.11)\n",
      "Requirement already satisfied: importlib_metadata==8.7.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (8.7.1)\n",
      "Requirement already satisfied: importlib_resources==6.5.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (6.5.2)\n",
      "Requirement already satisfied: ipykernel==7.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (7.2.0)\n",
      "Requirement already satisfied: ipython==9.10.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (9.10.0)\n",
      "Requirement already satisfied: ipython_pygments_lexers==1.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (1.1.1)\n",
      "Requirement already satisfied: jedi==0.19.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (0.19.2)\n",
      "Requirement already satisfied: Jinja2==3.1.6 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (3.1.6)\n",
      "Requirement already satisfied: jiter==0.13.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (0.13.0)\n",
      "Requirement already satisfied: jsonpatch==1.33 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (1.33)\n",
      "Requirement already satisfied: jsonpointer==3.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (3.0.0)\n",
      "Requirement already satisfied: jsonschema==4.26.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (4.26.0)\n",
      "Requirement already satisfied: jsonschema-specifications==2025.9.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (2025.9.1)\n",
      "Requirement already satisfied: jupyter_client==8.8.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (8.8.0)\n",
      "Requirement already satisfied: jupyter_core==5.9.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (5.9.1)\n",
      "Requirement already satisfied: jupyterlab_pygments==0.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (0.3.0)\n",
      "Requirement already satisfied: kubernetes==35.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (35.0.0)\n",
      "Requirement already satisfied: langchain==1.2.10 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (1.2.10)\n",
      "Requirement already satisfied: langchain-chroma==1.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (1.1.0)\n",
      "Requirement already satisfied: langchain-core==1.2.14 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (1.2.14)\n",
      "Requirement already satisfied: langchain-openai==1.1.10 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (1.1.10)\n",
      "Requirement already satisfied: langchain-text-splitters==1.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (1.1.1)\n",
      "Requirement already satisfied: langgraph==1.0.8 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (1.0.8)\n",
      "Requirement already satisfied: langgraph-checkpoint==4.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt==1.0.7 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk==0.3.7 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (0.3.7)\n",
      "Requirement already satisfied: langsmith==0.7.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (0.7.4)\n",
      "Requirement already satisfied: markdown-it-py==4.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (3.0.3)\n",
      "Requirement already satisfied: matplotlib-inline==0.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (0.2.1)\n",
      "Requirement already satisfied: mdurl==0.1.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (0.1.2)\n",
      "Requirement already satisfied: mmh3==5.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (5.2.0)\n",
      "Requirement already satisfied: mpmath==1.3.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (1.3.0)\n",
      "Requirement already satisfied: nbclient==0.10.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (0.10.4)\n",
      "Requirement already satisfied: nbformat==5.10.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (5.10.4)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (2.4.2)\n",
      "Requirement already satisfied: oauthlib==3.3.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (3.3.1)\n",
      "Requirement already satisfied: onnxruntime==1.24.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (1.24.2)\n",
      "Requirement already satisfied: openai==2.21.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (2.21.0)\n",
      "Requirement already satisfied: opentelemetry-api==1.39.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc==1.39.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.39.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk==1.39.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (0.60b1)\n",
      "Requirement already satisfied: orjson==3.11.7 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (3.11.7)\n",
      "Requirement already satisfied: ormsgpack==1.12.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 79)) (1.12.2)\n",
      "Requirement already satisfied: overrides==7.7.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 80)) (7.7.0)\n",
      "Requirement already satisfied: packaging==26.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 81)) (26.0)\n",
      "Requirement already satisfied: pandas==3.0.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 82)) (3.0.1)\n",
      "Requirement already satisfied: parso==0.8.6 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 83)) (0.8.6)\n",
      "Requirement already satisfied: pexpect==4.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 84)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.9.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 85)) (4.9.2)\n",
      "Requirement already satisfied: posthog==5.4.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 86)) (5.4.0)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.52 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 87)) (3.0.52)\n",
      "Requirement already satisfied: protobuf==6.33.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 88)) (6.33.5)\n",
      "Requirement already satisfied: psutil==7.2.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 89)) (7.2.2)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 90)) (0.2.3)\n",
      "Requirement already satisfied: pybase64==1.4.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 91)) (1.4.3)\n",
      "Requirement already satisfied: pydantic==2.12.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 92)) (2.12.5)\n",
      "Requirement already satisfied: pydantic_core==2.41.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 93)) (2.41.5)\n",
      "Requirement already satisfied: Pygments==2.19.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 94)) (2.19.2)\n",
      "Requirement already satisfied: PyMuPDF==1.27.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 95)) (1.27.1)\n",
      "Requirement already satisfied: PyPika==0.51.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 96)) (0.51.1)\n",
      "Requirement already satisfied: pyproject_hooks==1.2.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 97)) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 98)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv==1.2.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 99)) (1.2.1)\n",
      "Requirement already satisfied: PyYAML==6.0.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 100)) (6.0.3)\n",
      "Requirement already satisfied: pyzmq==27.1.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 101)) (27.1.0)\n",
      "Requirement already satisfied: rank-bm25==0.2.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 102)) (0.2.2)\n",
      "Requirement already satisfied: referencing==0.37.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 103)) (0.37.0)\n",
      "Requirement already satisfied: regex==2026.1.15 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 104)) (2026.1.15)\n",
      "Requirement already satisfied: requests==2.32.5 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 105)) (2.32.5)\n",
      "Requirement already satisfied: requests-oauthlib==2.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 106)) (2.0.0)\n",
      "Requirement already satisfied: requests-toolbelt==1.0.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 107)) (1.0.0)\n",
      "Requirement already satisfied: rich==14.3.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 108)) (14.3.3)\n",
      "Requirement already satisfied: rpds-py==0.30.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 109)) (0.30.0)\n",
      "Requirement already satisfied: shellingham==1.5.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 110)) (1.5.4)\n",
      "Requirement already satisfied: six==1.17.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 111)) (1.17.0)\n",
      "Requirement already satisfied: sniffio==1.3.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 112)) (1.3.1)\n",
      "Requirement already satisfied: soupsieve==2.8.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 113)) (2.8.3)\n",
      "Requirement already satisfied: stack-data==0.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 114)) (0.6.3)\n",
      "Requirement already satisfied: starlette==0.52.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 115)) (0.52.1)\n",
      "Requirement already satisfied: sympy==1.14.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 116)) (1.14.0)\n",
      "Requirement already satisfied: tenacity==9.1.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 117)) (9.1.4)\n",
      "Requirement already satisfied: tiktoken==0.12.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 118)) (0.12.0)\n",
      "Requirement already satisfied: tokenizers==0.22.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 119)) (0.22.2)\n",
      "Requirement already satisfied: tornado==6.5.4 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 120)) (6.5.4)\n",
      "Requirement already satisfied: tqdm==4.67.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 121)) (4.67.3)\n",
      "Requirement already satisfied: traitlets==5.14.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 122)) (5.14.3)\n",
      "Requirement already satisfied: typer==0.24.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 123)) (0.24.0)\n",
      "Requirement already satisfied: typer-slim==0.24.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 124)) (0.24.0)\n",
      "Requirement already satisfied: typing-inspection==0.4.2 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 125)) (0.4.2)\n",
      "Requirement already satisfied: typing_extensions==4.15.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 126)) (4.15.0)\n",
      "Requirement already satisfied: urllib3==2.6.3 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 127)) (2.6.3)\n",
      "Requirement already satisfied: uuid_utils==0.14.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 128)) (0.14.0)\n",
      "Requirement already satisfied: uvicorn==0.41.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 129)) (0.41.0)\n",
      "Requirement already satisfied: watchfiles==1.1.1 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 130)) (1.1.1)\n",
      "Requirement already satisfied: wcwidth==0.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 131)) (0.6.0)\n",
      "Requirement already satisfied: websocket-client==1.9.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 132)) (1.9.0)\n",
      "Requirement already satisfied: websockets==16.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 133)) (16.0)\n",
      "Requirement already satisfied: xxhash==3.6.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 134)) (3.6.0)\n",
      "Requirement already satisfied: zipp==3.23.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 135)) (3.23.0)\n",
      "Requirement already satisfied: zstandard==0.25.0 in ./.venv/lib/python3.12/site-packages (from -r requirements.txt (line 136)) (0.25.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in ./.venv/lib/python3.12/site-packages (from huggingface_hub==1.4.1->-r requirements.txt (line 31)) (1.2.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.12/site-packages (from pexpect==4.9.0->-r requirements.txt (line 84)) (0.7.0)\n",
      "Requirement already satisfied: uvloop>=0.15.1 in ./.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==1.5.0->-r requirements.txt (line 12)) (0.22.1)\n"
     ]
    }
   ],
   "source": [
    "# dependencies\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b232ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded.\n",
      "PDFs found: 89\n"
     ]
    }
   ],
   "source": [
    "# import + config\n",
    "\n",
    "import os\n",
    "import re\n",
    "import hashlib\n",
    "import json\n",
    "import pymupdf\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from rank_bm25 import BM25Okapi\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import chromadb\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "PDF_DIR = Path(\"quilter pdfs - advisor support material\")\n",
    "CHROMA_DIR = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"quilter_docs\"\n",
    "\n",
    "print(\"Config loaded.\")\n",
    "print(f\"PDFs found: {len(list(PDF_DIR.glob('*.pdf')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f095981",
   "metadata": {},
   "source": [
    "## PDF Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843f7b6a",
   "metadata": {},
   "source": [
    "PDFs are extracted using PyMuPDF, chosen for its preservation of block-level layout structure - important for Quilter documents which mix tables, bullet points, and flowing prose.  \n",
    "\n",
    "A boilerplate stripping pass removes recurring noise (page numbers, domain footers) that would otherwise inflate similarity scores between unrelated chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "972e8e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_4495/3526977869.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  \"\"\"def extract_pages(pdf_path):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 482 pages from 89 PDFs\n"
     ]
    }
   ],
   "source": [
    "# pdf extraction\n",
    "\"\"\"def extract_pages(pdf_path):\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    pages = []\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\").strip()\n",
    "        pages.append({\n",
    "            \"source\": Path(pdf_path).name,\n",
    "            \"page\": i + 1,\n",
    "            \"text\": text\n",
    "        })\n",
    "    doc.close()\n",
    "    return pages\n",
    "\n",
    "# boiler plate removal\n",
    "def strip_boilerplate(text):\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned = [\n",
    "        line for line in lines\n",
    "        if not re.match(r'^\\s*\\d+\\s*$', line) # lone page numbers\n",
    "        and \"quilter.com\" not in line.lower()\n",
    "        and \"quilter plc\" not in line.lower()\n",
    "        and len(line.strip()) > 2\n",
    "    ]\n",
    "    return \"\\n\".join(cleaned)\n",
    "\n",
    "all_pages = []\n",
    "for pdf in sorted(PDF_DIR.glob(\"*.pdf\")):\n",
    "    pages = extract_pages(pdf)\n",
    "    for p in pages:\n",
    "        p[\"text\"] = strip_boilerplate(p[\"text\"])\n",
    "    all_pages.extend(pages)\n",
    "\n",
    "print(f\"Extracted {len(all_pages)} pages from {len(list(PDF_DIR.glob('*.pdf')))} PDFs\")\"\"\"\n",
    "\n",
    "import pdfplumber\n",
    "\n",
    "# pdf extraction\n",
    "def extract_pages(pdf_path):\n",
    "    pages = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            text = page.extract_text() or \"\"\n",
    "            pages.append({\n",
    "                \"source\": Path(pdf_path).name,\n",
    "                \"page\": i + 1,\n",
    "                \"text\": text.strip()\n",
    "            })\n",
    "    return pages\n",
    "\n",
    "# boiler plate removal\n",
    "def strip_boilerplate(text):\n",
    "    \"\"\"Remove common Quilter header/footer noise.\"\"\"\n",
    "    lines = text.split(\"\\n\")\n",
    "    cleaned = [\n",
    "        line for line in lines\n",
    "        if not re.match(r'^\\s*\\d+\\s*$', line)  # lone page numbers\n",
    "        and \"quilter.com\" not in line.lower()\n",
    "        and \"quilter plc\" not in line.lower()\n",
    "        and len(line.strip()) > 2\n",
    "    ]\n",
    "    return \"\\n\".join(cleaned)\n",
    "\n",
    "all_pages = []\n",
    "for pdf in sorted(PDF_DIR.glob(\"*.pdf\")):\n",
    "    pages = extract_pages(pdf)\n",
    "    for p in pages:\n",
    "        p[\"text\"] = strip_boilerplate(p[\"text\"])\n",
    "    all_pages.extend(pages)\n",
    "\n",
    "print(f\"Extracted {len(all_pages)} pages from {len(list(PDF_DIR.glob('*.pdf')))} PDFs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c654ff9",
   "metadata": {},
   "source": [
    "## Chunking - Context Aware Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd470d3a",
   "metadata": {},
   "source": [
    "A two-pass context-aware strategy is applied over naive fixed-size splitting when chunking the PDFs.\n",
    "\n",
    "Pass 1 detects section boundaries using structural cues.\n",
    "\n",
    "Pass 2 applies RecursiveCharacterTextSplitter only to sections exceeding 1500 characters, splitting on paragraph breaks first, then if that fails, then sentences, then words.\n",
    "\n",
    "Every chunk is prefixed with its section heading to give the embedding model necessary local context. \n",
    "\n",
    "Each chunk carries an MD5 content hash serving two purposes: deduplication of boilerplate repeated across documents, and incremental re-indexing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "936371f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks before dedup: 1452\n",
      "Total chunks after dedup:  1422\n",
      "Avg chunk length: 885 chars\n"
     ]
    }
   ],
   "source": [
    "def extract_version_from_filename(filename):\n",
    "    match = re.search(r'[_\\-\\s]v(\\d+[\\.\\d]*)', filename, re.IGNORECASE)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    match = re.search(r'[_\\-\\s](\\d{4})', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return \"unknown\"\n",
    "\n",
    "def is_heading(line):\n",
    "    line = line.strip()\n",
    "    if not line or len(line) > 120:\n",
    "        return False\n",
    "    if line.isupper() and len(line) > 3:\n",
    "        return True\n",
    "    if re.match(r'^(\\d+\\.)+\\s+[A-Z]', line):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def split_into_sections(pages):\n",
    "    sections = []\n",
    "    current = {\"heading\": \"Introduction\", \"text\": \"\", \"pages\": [], \"source\": None}\n",
    "    for page in pages:\n",
    "        current[\"source\"] = page[\"source\"]\n",
    "        for line in page[\"text\"].split(\"\\n\"):\n",
    "            if is_heading(line):\n",
    "                if current[\"text\"].strip():\n",
    "                    sections.append(current.copy())\n",
    "                current = {\n",
    "                    \"heading\": line.strip(),\n",
    "                    \"text\": \"\",\n",
    "                    \"pages\": [page[\"page\"]],\n",
    "                    \"source\": page[\"source\"]\n",
    "                }\n",
    "            else:\n",
    "                current[\"text\"] += line + \"\\n\"\n",
    "                if page[\"page\"] not in current[\"pages\"]:\n",
    "                    current[\"pages\"].append(page[\"page\"])\n",
    "    if current[\"text\"].strip():\n",
    "        sections.append(current)\n",
    "    return sections\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"]\n",
    ")\n",
    "\n",
    "def make_chunk(text, source, pages, heading, chunk_index=0):\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"source\": source,\n",
    "        \"pages\": pages,\n",
    "        \"heading\": heading,\n",
    "        \"chunk_index\": chunk_index,\n",
    "        \"content_hash\": hashlib.md5(text.encode()).hexdigest(),\n",
    "        \"doc_version\": extract_version_from_filename(source)\n",
    "    }\n",
    "\n",
    "def chunk_sections(sections):\n",
    "    chunks = []\n",
    "    for section in sections:\n",
    "        full_text = f\"{section['heading']}\\n\\n{section['text']}\".strip()\n",
    "        if len(section[\"text\"]) < 1500:\n",
    "            chunks.append(make_chunk(full_text, section[\"source\"], section[\"pages\"], section[\"heading\"]))\n",
    "        else:\n",
    "            for i, sub in enumerate(splitter.split_text(section[\"text\"])):\n",
    "                sub_text = f\"{section['heading']}\\n\\n{sub}\".strip()\n",
    "                chunks.append(make_chunk(sub_text, section[\"source\"], section[\"pages\"], section[\"heading\"], i))\n",
    "    return chunks\n",
    "\n",
    "# Run it\n",
    "all_chunks = []\n",
    "for pdf in sorted(PDF_DIR.glob(\"*.pdf\")):\n",
    "    pages = extract_pages(pdf)\n",
    "    for p in pages:\n",
    "        p[\"text\"] = strip_boilerplate(p[\"text\"])\n",
    "    sections = split_into_sections(pages)\n",
    "    all_chunks.extend(chunk_sections(sections))\n",
    "\n",
    "# Deduplicate\n",
    "seen = {}\n",
    "deduped_chunks = []\n",
    "for chunk in all_chunks:\n",
    "    if chunk[\"content_hash\"] not in seen:\n",
    "        seen[chunk[\"content_hash\"]] = True\n",
    "        deduped_chunks.append(chunk)\n",
    "\n",
    "print(f\"Total chunks before dedup: {len(all_chunks)}\")\n",
    "print(f\"Total chunks after dedup:  {len(deduped_chunks)}\")\n",
    "print(f\"Avg chunk length: {sum(len(c['text']) for c in deduped_chunks) / len(deduped_chunks):.0f} chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb4f1b",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9143a397",
   "metadata": {},
   "source": [
    "A simple ChromaDB for a local persistent vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f39d2b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 1422 chunks into ChromaDB at ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "texts = [c[\"text\"] for c in deduped_chunks]\n",
    "metadatas = [\n",
    "    {\n",
    "        \"source\": c[\"source\"],\n",
    "        \"pages\": str(c[\"pages\"]),\n",
    "        \"heading\": c[\"heading\"],\n",
    "        \"chunk_index\": c[\"chunk_index\"],\n",
    "        \"content_hash\": c[\"content_hash\"],\n",
    "        \"doc_version\": c[\"doc_version\"]\n",
    "    }\n",
    "    for c in deduped_chunks\n",
    "]\n",
    "vectorstore = Chroma.from_texts(\n",
    "    texts=texts,\n",
    "    embedding=embeddings,\n",
    "    metadatas=metadatas,\n",
    "    persist_directory=CHROMA_DIR,\n",
    "    collection_name=COLLECTION_NAME\n",
    ")\n",
    "print(f\"Indexed {len(texts)} chunks into ChromaDB at {CHROMA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ce10d",
   "metadata": {},
   "source": [
    "## Retrieval - Hybrid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7268e7be",
   "metadata": {},
   "source": [
    "Combination of dense vector search with sparse BM25. Results are merged using RFF rewarding documents ranked highly by both retrievers. Retrieval count defaults to a fixed k=6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b017ecec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid retriever ready.\n"
     ]
    }
   ],
   "source": [
    "# BM25 sparse retriever\n",
    "tokenized_corpus = [c[\"text\"].lower().split() for c in deduped_chunks]\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "\n",
    "\n",
    "def hybrid_retrieve(query, k=6):\n",
    "    \"\"\"Combine dense (ChromaDB) and sparse (BM25) retrieval with RRF.\"\"\"\n",
    "    \n",
    "    # Dense retrieval\n",
    "    dense_results = vectorstore.similarity_search_with_score(query, k=k*2)\n",
    "    dense_ranked = {r[0].page_content: i for i, r in enumerate(dense_results)}\n",
    "    \n",
    "    # Sparse BM25 retrieval\n",
    "    tokenized_query = query.lower().split()\n",
    "    bm25_scores = bm25.get_scores(tokenized_query)\n",
    "    bm25_top_indices = np.argsort(bm25_scores)[::-1][:k*2]\n",
    "    bm25_ranked = {deduped_chunks[i][\"text\"]: rank for rank, i in enumerate(bm25_top_indices)}\n",
    "    \n",
    "    # Reciprocal Rank Fusion\n",
    "    all_texts = set(dense_ranked.keys()) | set(bm25_ranked.keys())\n",
    "    rrf_scores = {}\n",
    "    for text in all_texts:\n",
    "        dense_rank = dense_ranked.get(text, k*2)\n",
    "        bm25_rank = bm25_ranked.get(text, k*2)\n",
    "        rrf_scores[text] = 1/(60 + dense_rank) + 1/(60 + bm25_rank)\n",
    "    \n",
    "    top_texts = sorted(rrf_scores, key=rrf_scores.get, reverse=True)[:k]\n",
    "    \n",
    "    # Fetch full chunk metadata for top results\n",
    "    results = []\n",
    "    text_to_chunk = {c[\"text\"]: c for c in deduped_chunks}\n",
    "    for text in top_texts:\n",
    "        if text in text_to_chunk:\n",
    "            results.append(text_to_chunk[text])\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "print(\"Hybrid retriever ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5852c67",
   "metadata": {},
   "source": [
    "## Answer Generation &  Guardrail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcada3f",
   "metadata": {},
   "source": [
    "Strict prompt, temperature at 0, fallback can be triggered with the first response or via checkfaithfulness gaurdrail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c798afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer generation ready.\n"
     ]
    }
   ],
   "source": [
    "# answer generation with guardrails\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"You are an assistant that helps Quilter financial advisers answer operational questions.\n",
    "\n",
    "STRICT RULES:\n",
    "1. Answer ONLY using the context provided below. Do not use any outside knowledge.\n",
    "2. If the context does not contain enough information to answer the question, respond with exactly:\n",
    "   \"Please reach out to the Contact Centre.\"\n",
    "3. Always cite your sources using the format [Source: filename, p.X] at the end of each point.\n",
    "4. Do not give financial advice. Only explain processes and operational steps.\n",
    "5. Be concise and structured. Use bullet points for multi-step processes.\n",
    "\"\"\"\n",
    "\n",
    "def check_faithfulness(answer, context_texts):\n",
    "    \"\"\"Ask GPT to verify the answer is grounded in the context.\"\"\"\n",
    "    context_combined = \"\\n\\n\".join(context_texts[:4])\n",
    "    check_prompt = f\"\"\"Given this context:\n",
    "{context_combined}\n",
    "\n",
    "And this answer:\n",
    "{answer}\n",
    "\n",
    "Does every factual claim in the answer appear in the context? \n",
    "Reply with JSON only: {{\"faithful\": true/false, \"reason\": \"brief explanation\"}}\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # cheaper model for this check\n",
    "        messages=[{\"role\": \"user\", \"content\": check_prompt}],\n",
    "        temperature=0\n",
    "    )\n",
    "    try:\n",
    "        return json.loads(response.choices[0].message.content)\n",
    "    except:\n",
    "        return {\"faithful\": True, \"reason\": \"Could not parse faithfulness check\"}\n",
    "\n",
    "\n",
    "def answer_query(query, k=6, check_grounding=True):\n",
    "    # Retrieve relevant chunks\n",
    "    retrieved = hybrid_retrieve(query, k=k)\n",
    "    \n",
    "    if not retrieved:\n",
    "        return {\n",
    "            \"answer\": \"Please reach out to the Contact Centre.\",\n",
    "            \"sources\": [],\n",
    "            \"faithful\": None,\n",
    "            \"chunks_used\": 0\n",
    "        }\n",
    "    \n",
    "    # Build context string\n",
    "    context_parts = []\n",
    "    for chunk in retrieved:\n",
    "        source_label = f\"[Source: {chunk['source']}, p.{chunk['pages']}]\"\n",
    "        context_parts.append(f\"{source_label}\\n{chunk['text']}\")\n",
    "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Generate answer\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"Context:\\n{context}\\n\\nQuestion: {query}\"}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    \n",
    "    # Faithfulness check\n",
    "    faithfulness = None\n",
    "    if check_grounding:\n",
    "        faithfulness = check_faithfulness(answer, [c[\"text\"] for c in retrieved])\n",
    "        if not faithfulness[\"faithful\"]:\n",
    "            answer = \"Please reach out to the Contact Centre.\"\n",
    "    \n",
    "    return {\n",
    "        \"answer\": answer,\n",
    "        \"sources\": [{\"source\": c[\"source\"], \"pages\": c[\"pages\"], \"heading\": c[\"heading\"]} for c in retrieved],\n",
    "        \"faithful\": faithfulness,\n",
    "        \"chunks_used\": len(retrieved)\n",
    "    }\n",
    "\n",
    "    \n",
    "print(\"Answer generation ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d8aec8",
   "metadata": {},
   "source": [
    "## Local FastAPI Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbef87e",
   "metadata": {},
   "source": [
    "Two routes are provided: /health for server status and /ask for query submission, with configurable parameters for retrieval depth and guardrail toggling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12883e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastAPI running at http://localhost:8000\n",
      "Docs at http://localhost:8000/docs\n"
     ]
    }
   ],
   "source": [
    "# FastAPI app\n",
    "\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "import threading\n",
    "\n",
    "nest_asyncio.apply()  # allows FastAPI to run inside a Jupyter notebook\n",
    "\n",
    "app = FastAPI(title=\"Quilter Advisor Assistant\")\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")\n",
    "\n",
    "class QueryRequest(BaseModel):\n",
    "    query: str\n",
    "    k: int = 6\n",
    "    check_grounding: bool = True\n",
    "\n",
    "\n",
    "class QueryResponse(BaseModel):\n",
    "    answer: str\n",
    "    sources: list\n",
    "    faithful: dict | None\n",
    "    chunks_used: int\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\", \"chunks_indexed\": len(deduped_chunks)}\n",
    "\n",
    "@app.post(\"/ask\", response_model=QueryResponse)\n",
    "def ask(request: QueryRequest):\n",
    "    result = answer_query(request.query, k=request.k, check_grounding=request.check_grounding)\n",
    "    return result\n",
    "\n",
    "# Run in background thread so notebook stays interactive\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"warning\")\n",
    "\n",
    "thread = threading.Thread(target=run_server, daemon=True)\n",
    "thread.start()\n",
    "\n",
    "print(\"FastAPI running at http://localhost:8000\")\n",
    "print(\"Docs at http://localhost:8000/docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5adb0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server is up: {'status': 'ok', 'chunks_indexed': 1422}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "time.sleep(2)  # give the thread a moment to start\n",
    "\n",
    "import requests\n",
    "try:\n",
    "    r = requests.get(\"http://localhost:8000/health\", timeout=3)\n",
    "    print(\"Server is up:\", r.json())\n",
    "except Exception as e:\n",
    "    print(\"Server not running:\", e)\n",
    "    print(\"\\nCheck that Cell 8 ran without errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb880a",
   "metadata": {},
   "source": [
    "Test a single question and answer..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddf94f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'ok', 'chunks_indexed': 1422}\n",
      "\n",
      "=== ANSWER ===\n",
      "Please reach out to the Contact Centre.\n",
      "\n",
      "=== SOURCES ===\n",
      "  - 18152-isa-aps-options--for-deaths-before-6-april-2018.pdf | Introduction | pp.[1]\n",
      "  - accepting_documentation_via_email_and_prompt.pdf | Introduction | pp.[1, 2, 3]\n",
      "  - 18051-isa-aps-options-after-6-april.pdf | Introduction | pp.[1]\n",
      "  - 18051-isa-aps-options-after-6-april.pdf | 2. If the deceased had an ISA with another ISA manager, the options are: | pp.[3]\n",
      "  - 23625-release-of-information-request.pdf | Introduction | pp.[1]\n",
      "  - 18051-isa-aps-options-after-6-april.pdf | YES NO | pp.[1]\n",
      "\n",
      "=== GROUNDING CHECK ===\n",
      "{'faithful': False, 'reason': 'The answer does not provide any specific information or context related to the Additional Permitted Subscription (APS) or the eligibility criteria mentioned in the provided context.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "# Test the health endpoint\n",
    "print(requests.get(\"http://localhost:8000/health\").json())\n",
    "\n",
    "# Test a query\n",
    "response = requests.post(\"http://localhost:8000/ask\", json={\n",
    "    \"query\": \"What are the requirements to complete an ISA transfer?\",\n",
    "    \"k\": 6,\n",
    "    \"check_grounding\": True\n",
    "})\n",
    "\n",
    "result = response.json()\n",
    "print(\"\\n=== ANSWER ===\")\n",
    "print(result[\"answer\"])\n",
    "print(\"\\n=== SOURCES ===\")\n",
    "for s in result[\"sources\"]:\n",
    "    print(f\"  - {s['source']} | {s['heading']} | pp.{s['pages']}\")\n",
    "print(\"\\n=== GROUNDING CHECK ===\")\n",
    "print(result[\"faithful\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb072536",
   "metadata": {},
   "source": [
    "# Offline Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452aeb5a",
   "metadata": {},
   "source": [
    "## Annotated Evaluation Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a08d4eb",
   "metadata": {},
   "source": [
    "11 manually created Question answer pairs with source documentation and location within the source.\n",
    "5 out of scope questions specifically for refusal rate testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0bbadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_SET = [\n",
    "    {\n",
    "        \"question\": \"What is Quilter's Absolute Trust?\",\n",
    "        \"expected_answer\": \"A simple IHT solution where the client does not require access to the capital, knows who they want to leave their wealth to, and requires no future flexibility.\",\n",
    "        \"source_pdf\": \"20881-understanding-our-range-of-trusts.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"When is Life Fund Tax Charge Taken?\",\n",
    "        \"expected_answer\": \"The charge is taken at numerous points through the year.\",\n",
    "        \"source_pdf\": \"7910-taxation-for-quilter-life-funds.pdf\",\n",
    "        \"source_pages\": [4],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is the Quilter Smoothed Balanced Fund (Standard Life) a suitable choice for?\",\n",
    "        \"expected_answer\": \"The funds may be suitable for an investor who is approaching or is in retirement, wants to reduce day-to-day fluctuations, is looking to potentially grow their investment, is willing to accept some risk, intends to invest for at least five years, wants to take an income, and has a financial adviser.\",\n",
    "        \"source_pdf\": \"kiid-gb00bt9lzb27-en-gb.pdf\",\n",
    "        \"source_pages\": [2],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are investment pathways?\",\n",
    "        \"expected_answer\": \"Instead of having to choose an investment for your drawdown pot, you choose from four options that closely match what you would like to do with your money in the next 5 years.\",\n",
    "        \"source_pdf\": \"20993-what-you-need-to-know-about-investment-pathways.pdf\",\n",
    "        \"source_pages\": [3],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are share identification rules?\",\n",
    "        \"expected_answer\": \"Rules that ended bed and breakfasting by matching disposed units first with units acquired the same day, then units acquired in the following 30 days, then units in the Section 104 holding.\",\n",
    "        \"source_pdf\": \"20720-cgt-quick-reference-guide-3-share-identification-rules.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In the Legal Framework what is point 6.1.2?\",\n",
    "        \"expected_answer\": \"The Intermediary will be responsible for ensuring that only permitted individuals access and use the Services, and will be liable for any acts or omissions resulting from use of User Access by any of its Users.\",\n",
    "        \"source_pdf\": \"7161_legal_framework.pdf\",\n",
    "        \"source_pages\": [3],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"In the Legal Framework, what is the policy on Third Party suppliers?\",\n",
    "        \"expected_answer\": \"Third party providers may require an Intermediary or User to agree to additional terms for use of their software or services, without prejudice to the obligations of the Parties under the Agreement.\",\n",
    "        \"source_pdf\": \"7161_legal_framework.pdf\",\n",
    "        \"source_pages\": [5],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is an Additional Permitted Subscription (APS)?\",\n",
    "        \"expected_answer\": \"When an ISA investor dies on or after 3 December 2014, a surviving spouse is entitled to invest into an ISA over and above the annual ISA allowance, known as an Additional Permitted Subscription or APS.\",\n",
    "        \"source_pdf\": \"18152-isa-aps-options--for-deaths-before-6-april-2018.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can you complete the Intermediary Resignation Form?\",\n",
    "        \"expected_answer\": \"Either electronically by saving and opening in Adobe Acrobat to complete editable fields then signing, or by hand by printing and completing in block capitals using blue or black ink.\",\n",
    "        \"source_pdf\": \"19502-intermediary-registration-form.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the objectives of the WealthSelect Sustainable Portfolios?\",\n",
    "        \"expected_answer\": \"To achieve capital growth over five or more years whilst supporting sustainable solutions to environmental and social challenges aligned with UN Sustainable Development Goals, managing ESG risks and maintaining a smaller carbon footprint than the MSCI ACWI reference index.\",\n",
    "        \"source_pdf\": \"11541_wealthselect_due_dilligence.pdf\",\n",
    "        \"source_pages\": [5],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is reason number 1 for using onshore bonds?\",\n",
    "        \"expected_answer\": \"Tax deferral and control â€” clients are only assessable for tax when a chargeable event occurs, such as withdrawals over the 5% allowance, meaning they control when they report and pay tax.\",\n",
    "        \"source_pdf\": \"23416_six_reasons_why.pdf\",\n",
    "        \"source_pages\": [1],\n",
    "        \"type\": \"in-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How can I make money from Bitcoin?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What is the weather doing?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Who is Kai Glahome?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How do I increase my expected returns?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Where is London?\",\n",
    "        \"expected_answer\": None,\n",
    "        \"source_pdf\": None,\n",
    "        \"source_pages\": None,\n",
    "        \"type\": \"out-of-scope\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b98275",
   "metadata": {},
   "source": [
    "## Running Offline Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b366da",
   "metadata": {},
   "source": [
    "Offline Evaluation Metrics\n",
    "\n",
    "Subcategorised into retrieval, generation, and system... Discussed in the documentation why.\n",
    "\n",
    "**Retrieval** (first 3 derived from Recall@6)\n",
    "\n",
    "- **Source PDF Recall@6** â€” For each in-scope question, checks whether the correct source document appeared within the top 6 retrieved chunks. A score of 1.0 indicates perfect retrieval coverage.\n",
    "- **Page Recall@6** â€” For each in-scope question, checks whether the correct page appeared within the top 6 retrieved chunks. A score of 1.0 indicates perfect page-level retrieval coverage.\n",
    "- **Avg Source Rank** â€” Where the correct document was retrieved, records its position in the results list. Lower is better â€” a rank of 1 means the correct document was the top result.\n",
    "- **Avg Redundancy Score** â€” Measures the proportion of retrieved chunks that came from distinct source documents. A score of 1.0 means all 6 chunks came from different documents; a lower score indicates multiple chunks from the same source.\n",
    "\n",
    "**Generation**\n",
    "\n",
    "- **Avg Correctness Score (LLM Judge)** â€” GPT-4o-mini judges each generated answer against the hand-crafted expected answer on a 1-3 scale: 1 = incorrect, 2 = partially correct, 3 = correct and complete.\n",
    "- **Avg Groundedness Score (LLM Judge)** â€” A separate LLM judge assesses whether the generated answer is grounded in the retrieved sources rather than outside knowledge, on a 1-3 scale.\n",
    "\n",
    "**System**\n",
    "\n",
    "- **Faithful Answers (LLM Judge)** â€” Count of in-scope answers that passed the inference-time faithfulness check. Failed answers are suppressed and replaced with the Contact Centre fallback.\n",
    "- **Refusal Accuracy** â€” Proportion of out-of-scope questions correctly deflected to the Contact Centre fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba42ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from typing import Optional\n",
    "\n",
    "def run_offline_evaluation(eval_set):\n",
    "    results = []\n",
    "    \n",
    "    for item in eval_set:\n",
    "        response = requests.post(\"http://localhost:8000/ask\", json={\n",
    "            \"query\": item[\"question\"],\n",
    "            \"k\": 6,\n",
    "            \"check_grounding\": True\n",
    "        })\n",
    "        result = response.json()\n",
    "        \n",
    "        answer = result[\"answer\"]\n",
    "        sources = result[\"sources\"]\n",
    "        faithful = result[\"faithful\"]\n",
    "        retrieved_pdfs = [s[\"source\"] for s in sources]\n",
    "        retrieved_pages = [p for s in sources for p in (eval(s[\"pages\"]) if isinstance(s[\"pages\"], str) else s[\"pages\"])]\n",
    "        \n",
    "        # --- Retrieval check (in-scope only) ---\n",
    "        source_hit = None\n",
    "        source_rank = None\n",
    "        page_hit = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            source_hit = item[\"source_pdf\"] in retrieved_pdfs\n",
    "            if source_hit:\n",
    "                source_rank = next(i+1 for i, pdf in enumerate(retrieved_pdfs) if pdf == item[\"source_pdf\"])\n",
    "            page_hit = any(p in retrieved_pages for p in item[\"source_pages\"])\n",
    "\n",
    "        # --- Retrieval redundancy (in-scope only) ---\n",
    "        redundancy_score = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            distinct_pdfs = len(set(retrieved_pdfs))\n",
    "            redundancy_score = round(distinct_pdfs / len(retrieved_pdfs), 2)\n",
    "\n",
    "        # --- Refusal check (out-of-scope only) ---\n",
    "        correctly_refused = None\n",
    "        if item[\"type\"] == \"out-of-scope\":\n",
    "            correctly_refused = \"contact centre\" in answer.lower()\n",
    "\n",
    "        # --- LLM-as-judge answer correctness (in-scope only) ---\n",
    "        llm_score = None\n",
    "        llm_reasoning = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            judge_prompt = f\"\"\"You are evaluating an AI assistant's answer against a known correct answer.\n",
    "\n",
    "Question: {item[\"question\"]}\n",
    "Expected Answer: {item[\"expected_answer\"]}\n",
    "Generated Answer: {answer}\n",
    "\n",
    "Score the generated answer on a scale of 1-3:\n",
    "1 = Incorrect or missing key information\n",
    "2 = Partially correct, captures some but not all key points\n",
    "3 = Correct and complete\n",
    "\n",
    "Respond with JSON only: {{\"score\": <1-3>, \"reasoning\": \"<brief explanation>\"}}\"\"\"\n",
    "\n",
    "            judge_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": judge_prompt}],\n",
    "                temperature=0\n",
    "            )\n",
    "            try:\n",
    "                judge_result = json.loads(judge_response.choices[0].message.content)\n",
    "                llm_score = judge_result[\"score\"]\n",
    "                llm_reasoning = judge_result[\"reasoning\"]\n",
    "            except:\n",
    "                llm_score = None\n",
    "                llm_reasoning = \"Parse error\"\n",
    "\n",
    "        # --- LLM-as-judge groundedness (in-scope only) ---\n",
    "        groundedness_score = None\n",
    "        groundedness_reasoning = None\n",
    "        if item[\"type\"] == \"in-scope\":\n",
    "            groundedness_prompt = f\"\"\"You are evaluating whether an AI assistant's answer is grounded in the retrieved documents.\n",
    "\n",
    "Retrieved Sources: {[s['source'] for s in sources]}\n",
    "Generated Answer: {answer}\n",
    "\n",
    "Does the answer contain only information that could plausibly come from the retrieved sources, or does it appear to include invented or outside knowledge?\n",
    "\n",
    "Score on a scale of 1-3:\n",
    "1 = Answer contains claims not supported by retrieved sources\n",
    "2 = Answer is mostly grounded but contains some unsupported claims\n",
    "3 = Answer is fully grounded in the retrieved sources\n",
    "\n",
    "Respond with JSON only: {{\"score\": <1-3>, \"reasoning\": \"<brief explanation>\"}}\"\"\"\n",
    "\n",
    "            groundedness_response = client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                messages=[{\"role\": \"user\", \"content\": groundedness_prompt}],\n",
    "                temperature=0\n",
    "            )\n",
    "            try:\n",
    "                groundedness_result = json.loads(groundedness_response.choices[0].message.content)\n",
    "                groundedness_score = groundedness_result[\"score\"]\n",
    "                groundedness_reasoning = groundedness_result[\"reasoning\"]\n",
    "            except:\n",
    "                groundedness_score = None\n",
    "                groundedness_reasoning = \"Parse error\"\n",
    "\n",
    "        results.append({\n",
    "            \"question\": item[\"question\"],\n",
    "            \"type\": item[\"type\"],\n",
    "            \"answer_preview\": answer[:200],\n",
    "            \"source_hit\": source_hit,\n",
    "            \"source_rank\": source_rank,\n",
    "            \"page_hit\": page_hit,\n",
    "            \"redundancy_score\": redundancy_score,\n",
    "            \"correctly_refused\": correctly_refused,\n",
    "            \"llm_score\": llm_score,\n",
    "            \"llm_reasoning\": llm_reasoning,\n",
    "            \"groundedness_score\": groundedness_score,\n",
    "            \"groundedness_reasoning\": groundedness_reasoning,\n",
    "            \"faithful\": faithful\n",
    "        })\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86c29c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it\n",
    "results = run_offline_evaluation(EVAL_SET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a80d58e",
   "metadata": {},
   "source": [
    "## Results and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d757ebac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_evaluation_report(results):\n",
    "    in_scope = [r for r in results if r[\"type\"] == \"in-scope\"]\n",
    "    out_scope = [r for r in results if r[\"type\"] == \"out-of-scope\"]\n",
    "\n",
    "    # Compute metrics\n",
    "    recall = sum(1 for r in in_scope if r[\"source_hit\"]) / len(in_scope)\n",
    "    avg_rank = sum(r[\"source_rank\"] for r in in_scope if r[\"source_rank\"]) / max(sum(1 for r in in_scope if r[\"source_rank\"]), 1)\n",
    "    page_recall = sum(1 for r in in_scope if r[\"page_hit\"]) / len(in_scope)\n",
    "    avg_redundancy = sum(r[\"redundancy_score\"] for r in in_scope if r[\"redundancy_score\"] is not None) / len(in_scope)\n",
    "    scored = [r for r in in_scope if r[\"llm_score\"]]\n",
    "    avg_llm_score = sum(r[\"llm_score\"] for r in scored) / max(len(scored), 1)\n",
    "    scored_grounded = [r for r in in_scope if r[\"groundedness_score\"]]\n",
    "    avg_groundedness = sum(r[\"groundedness_score\"] for r in scored_grounded) / max(len(scored_grounded), 1)\n",
    "    faithful_count = sum(1 for r in in_scope if r[\"faithful\"] and r[\"faithful\"].get(\"faithful\"))\n",
    "    refusal_accuracy = sum(1 for r in out_scope if r[\"correctly_refused\"]) / len(out_scope)\n",
    "\n",
    "    # Summary table\n",
    "    print(\"=\" * 60)\n",
    "    print(\"OFFLINE EVALUATION REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    summary_data = {\n",
    "        \"Metric\": [\n",
    "            \"Source PDF Recall@6\",\n",
    "            \"Page Recall@6\",\n",
    "            \"Avg Source Rank (lower = better)\",\n",
    "            \"Avg Redundancy Score (1.0 = fully diverse)\",\n",
    "            \"Avg Correctness Score (LLM Judge) /3\",\n",
    "            \"Avg Groundedness Score (LLM Judge) /3\",\n",
    "            f\"Faithful Answers\",\n",
    "            \"Refusal Accuracy (out-of-scope)\"\n",
    "        ],\n",
    "        \"Value\": [\n",
    "            f\"{recall:.2f}\",\n",
    "            f\"{page_recall:.2f}\",\n",
    "            f\"{avg_rank:.1f}\",\n",
    "            f\"{avg_redundancy:.2f}\",\n",
    "            f\"{avg_llm_score:.2f}\",\n",
    "            f\"{avg_groundedness:.2f}\",\n",
    "            f\"{faithful_count}/{len(in_scope)}\",\n",
    "            f\"{refusal_accuracy:.2f}\"\n",
    "        ]\n",
    "    }\n",
    "    print(pd.DataFrame(summary_data).to_string(index=False))\n",
    "\n",
    "    # Per question breakdown\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PER QUESTION BREAKDOWN\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for r in results:\n",
    "        print(f\"\\n{'â”€' * 60}\")\n",
    "        print(f\"Q:  {r['question'][:80]}\")\n",
    "        print(f\"    Type: {r['type'].upper()}\")\n",
    "        if r[\"type\"] == \"in-scope\":\n",
    "            print(f\"    Source Hit:   {'âœ“' if r['source_hit'] else 'âœ—'} (rank {r['source_rank']})\")\n",
    "            print(f\"    Page Hit:     {'âœ“' if r['page_hit'] else 'âœ—'}\")\n",
    "            print(f\"    Redundancy:   {r['redundancy_score']}\")\n",
    "            print(f\"    Correctness:  {r['llm_score']}/3 â€” {r['llm_reasoning']}\")\n",
    "            print(f\"    Groundedness: {r['groundedness_score']}/3 â€” {r['groundedness_reasoning']}\")\n",
    "            print(f\"    Faithful:     {'âœ“' if r['faithful'] and r['faithful'].get('faithful') else 'âœ—'}\")\n",
    "        else:\n",
    "            print(f\"    Refused:      {'âœ“' if r['correctly_refused'] else 'âœ—'}\")\n",
    "        print(f\"    Preview:      {r['answer_preview'][:150]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6b3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OFFLINE EVALUATION REPORT\n",
      "============================================================\n",
      "                                    Metric Value\n",
      "                       Source PDF Recall@6  0.91\n",
      "                             Page Recall@6  0.91\n",
      "          Avg Source Rank (lower = better)   1.4\n",
      "Avg Redundancy Score (1.0 = fully diverse)  0.47\n",
      "      Avg Correctness Score (LLM Judge) /3  1.82\n",
      "     Avg Groundedness Score (LLM Judge) /3  2.45\n",
      "                          Faithful Answers  7/11\n",
      "           Refusal Accuracy (out-of-scope)  1.00\n",
      "\n",
      "============================================================\n",
      "PER QUESTION BREAKDOWN\n",
      "============================================================\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  What is Quilter's Absolute Trust?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ— (rank None)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   1.0\n",
      "    Correctness:  1/3 â€” The generated answer does not provide any information about Quilter's Absolute Trust and instead directs the user to contact a center, missing all key points of the expected answer.\n",
      "    Groundedness: 1/3 â€” The answer 'Please reach out to the Contact Centre' does not appear to be supported by any of the retrieved documents, which focus on trust registration, investment bonds, and due diligence, rather than providing contact information or instructions.\n",
      "    Faithful:     âœ—\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  When is Life Fund Tax Charge Taken?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.17\n",
      "    Correctness:  3/3 â€” The generated answer correctly states that the Life Fund Tax Charge is taken at numerous points throughout the year and provides specific examples of when the charge is applied, aligning with the expected answer.\n",
      "    Groundedness: 3/3 â€” The answer is fully grounded in the retrieved source, as it accurately reflects the information regarding the Life Fund Tax Charge and the specific events during which it is deducted, all of which are supported by the content of the provided document.\n",
      "    Faithful:     âœ“\n",
      "    Preview:      - The Life Fund Tax Charge is taken at numerous points throughout the year. [Source: 7910-taxation-for-quilter-life-funds.pdf, p.1]\n",
      "- It is specifical\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  Who is the Quilter Smoothed Balanced Fund (Standard Life) a suitable choice for?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.5\n",
      "    Correctness:  1/3 â€” The generated answer only mentions that the fund is suitable for retail clients, which is vague and does not address the specific criteria outlined in the expected answer.\n",
      "    Groundedness: 3/3 â€” The answer states that the Quilter Smoothed Balanced Fund is suitable for retail clients, which is a claim that could plausibly be found in the retrieved documents, specifically in the KIID (Key Investor Information Document) referenced.\n",
      "    Faithful:     âœ“\n",
      "    Preview:      - The Quilter Smoothed Balanced Fund (Standard Life) is suitable for retail clients [Source: kiid-gb00bt9lzb27-en-gb.pdf, p.1].\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  What are investment pathways?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 5)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.33\n",
      "    Correctness:  1/3 â€” The generated answer does not address the question about investment pathways and instead suggests contacting a support center, missing all key information.\n",
      "    Groundedness: 3/3 â€” The answer suggests reaching out to the Contact Centre, which is a plausible action that could be supported by the content typically found in due diligence or investment pathway documents.\n",
      "    Faithful:     âœ—\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  What are share identification rules?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.83\n",
      "    Correctness:  2/3 â€” The generated answer captures the essence of share identification rules and mentions their role in preventing bed and breakfasting, but it does not explicitly detail the specific matching process outlined in the expected answer.\n",
      "    Groundedness: 3/3 â€” The answer is fully grounded in the retrieved sources, specifically referencing the share identification rules and their historical context as described in the document '20720-cgt-quick-reference-guide-3-share-identification-rules.pdf'.\n",
      "    Faithful:     âœ“\n",
      "    Preview:      - Share identification rules are used to calculate the Capital Gains realised on the disposal of shares or units in a collective investment scheme. Th\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  In the Legal Framework what is point 6.1.2?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ—\n",
      "    Redundancy:   0.17\n",
      "    Correctness:  1/3 â€” The generated answer does not address the question and fails to provide any relevant information about point 6.1.2.\n",
      "    Groundedness: 1/3 â€” The answer 'Please reach out to the Contact Centre' does not appear to be supported by the retrieved document, which is a legal framework. There is no indication that the document contains information about contacting a center.\n",
      "    Faithful:     âœ—\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  In the Legal Framework, what is the policy on Third Party suppliers?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.17\n",
      "    Correctness:  3/3 â€” The generated answer accurately captures all key points from the expected answer, including the requirement for additional terms from third-party providers and the clarification that these terms do not affect the obligations under the main Agreement.\n",
      "    Groundedness: 3/3 â€” The answer is fully grounded in the retrieved source, as it accurately reflects the content regarding third-party providers and additional terms related to the services, as stated in the legal framework document.\n",
      "    Faithful:     âœ“\n",
      "    Preview:      - The Legal Framework acknowledges that certain third-party providers of ancillary software or services may be used by the Provider, the Intermediary,\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  What is an Additional Permitted Subscription (APS)?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.33\n",
      "    Correctness:  3/3 â€” The generated answer accurately defines an Additional Permitted Subscription (APS) and includes all key points from the expected answer, including the context of a surviving spouse or civil partner and the relevant date.\n",
      "    Groundedness: 3/3 â€” The answer accurately describes the Additional Permitted Subscription (APS) and its relevance to surviving spouses or civil partners, which is consistent with the information provided in the retrieved sources.\n",
      "    Faithful:     âœ“\n",
      "    Preview:      - An Additional Permitted Subscription (APS) is an entitlement for a surviving spouse or civil partner to invest in an ISA over and above the annual I\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  How can you complete the Intermediary Resignation Form?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.67\n",
      "    Correctness:  2/3 â€” The generated answer captures the main methods for completing the form (electronically and manually) and provides additional details such as date format and submission methods. However, it includes extra information not present in the expected answer, such as the requirement for a letterhead and specific submission methods, which may not be necessary for the core response.\n",
      "    Groundedness: 3/3 â€” The answer provides detailed instructions on completing and submitting the intermediary registration form, which aligns with the content expected in a document titled '19502-intermediary-registration-form.pdf'. All the steps and requirements mentioned in the answer are plausible and consistent with what would be found in such a form.\n",
      "    Faithful:     âœ“\n",
      "    Preview:      - **Option 1 (Electronic Completion):**\n",
      "  - Save the form to your desktop.\n",
      "  - Open it in Adobe Acrobat to complete the editable fields.\n",
      "  - Either pr\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  What are the objectives of the WealthSelect Sustainable Portfolios?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.33\n",
      "    Correctness:  2/3 â€” The generated answer captures the objective of achieving capital growth over five or more years but omits key details about supporting sustainable solutions, managing ESG risks, and maintaining a smaller carbon footprint.\n",
      "    Groundedness: 3/3 â€” The answer is fully grounded in the retrieved source, specifically referencing the WealthSelect Sustainable Portfolios and their aim for capital growth over a specified period, which is consistent with the content expected in the provided document.\n",
      "    Faithful:     âœ“\n",
      "    Preview:      - The WealthSelect Sustainable Portfolios aim to achieve capital growth over a period of five years or more. [Source: 11541_wealthselect_due_dilligenc\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  What is reason number 1 for using onshore bonds?\n",
      "    Type: IN-SCOPE\n",
      "    Source Hit:   âœ“ (rank 1)\n",
      "    Page Hit:     âœ“\n",
      "    Redundancy:   0.67\n",
      "    Correctness:  1/3 â€” The generated answer does not address the question about the reason for using onshore bonds and instead suggests contacting a support center, missing the key information about tax deferral and control.\n",
      "    Groundedness: 1/3 â€” The answer 'Please reach out to the Contact Centre' does not reference or relate to any specific information from the retrieved documents, which focus on onshore and offshore bonds.\n",
      "    Faithful:     âœ—\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  How can I make money from Bitcoin?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      âœ“\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  What is the weather doing?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      âœ“\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  Who is Kai Glahome?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      âœ“\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  How do I increase my expected returns?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      âœ“\n",
      "    Preview:      Please reach out to the Contact Centre.\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Q:  Where is London?\n",
      "    Type: OUT-OF-SCOPE\n",
      "    Refused:      âœ“\n",
      "    Preview:      Please reach out to the Contact Centre.\n"
     ]
    }
   ],
   "source": [
    "print_evaluation_report(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
